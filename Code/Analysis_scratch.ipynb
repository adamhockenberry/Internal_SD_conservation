{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['xtick.labelsize'] = 20\n",
    "matplotlib.rcParams['ytick.labelsize'] = 20\n",
    "matplotlib.rcParams['axes.labelsize'] = 20\n",
    "matplotlib.rcParams['axes.titlesize'] = 20\n",
    "\n",
    "matplotlib.rcParams['axes.grid'] = True\n",
    "matplotlib.rcParams['grid.color'] = '0.5'\n",
    "matplotlib.rcParams['grid.linewidth'] = '0.5'\n",
    "\n",
    "matplotlib.rcParams['axes.edgecolor'] = '0.25'\n",
    "matplotlib.rcParams['xtick.color'] = '0'\n",
    "matplotlib.rcParams['ytick.color'] = '0'\n",
    "\n",
    "matplotlib.rcParams['xtick.major.width'] = 2\n",
    "matplotlib.rcParams['ytick.major.width'] = 2\n",
    "matplotlib.rcParams['ytick.major.size'] = 10\n",
    "matplotlib.rcParams['xtick.major.size'] = 10\n",
    "matplotlib.rcParams['axes.spines.right'] = False\n",
    "matplotlib.rcParams['axes.spines.left'] = False\n",
    "matplotlib.rcParams['axes.spines.top'] = False\n",
    "matplotlib.rcParams['axes.spines.bottom'] = False\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.weight']='ultralight'\n",
    "# matplotlib.rcParams['font.sans-serif'] = ['Computer Modern Sans Serif']\n",
    "matplotlib.rcParams['axes.axisbelow'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from scipy import stats\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from Bio.Data import CodonTable\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(list(range(10)), list(range(10)), color='steelblue', linestyle='', marker='o')\n",
    "# plt.xlabel('howdy yall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_codon_dicts(n=11):\n",
    "    GivenCodonTable = CodonTable.unambiguous_dna_by_id[n]\n",
    "    nucleotides = ['A', 'T', 'C', 'G']\n",
    "    aa_to_codons = {}\n",
    "    for first in nucleotides:\n",
    "        for second in nucleotides:\n",
    "            for third in nucleotides:\n",
    "                Codon = first + second + third\n",
    "                if Codon not in CodonTable.unambiguous_dna_by_id[n].stop_codons:\n",
    "                    if GivenCodonTable.forward_table[Codon] in aa_to_codons.keys():\n",
    "                            aa_to_codons[GivenCodonTable.forward_table[Codon]].append(Codon)\n",
    "                    else:\n",
    "                        aa_to_codons[GivenCodonTable.forward_table[Codon]] = [Codon]\n",
    "                else:\n",
    "                    pass\n",
    "    codon_to_aa = {}\n",
    "    for aa, syns in aa_to_codons.items():\n",
    "        for syn in syns:\n",
    "            codon_to_aa[syn] = aa\n",
    "    return aa_to_codons, codon_to_aa\n",
    "\n",
    "aa_to_codon_dict, codon_to_aa_dict = get_codon_dicts()\n",
    "\n",
    "temp = []\n",
    "for aa in ['P', 'T', 'A', 'V', 'G']:\n",
    "    temp.extend(aa_to_codon_dict[aa])\n",
    "\n",
    "redundant_codons = ['CTA', 'CTG', 'CTC', 'CTT',\\\n",
    "                    'TCA', 'TCG', 'TCC', 'TCT',\\\n",
    "                    'CGA', 'CGG', 'CGC', 'CGT'] + temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the sequences for each gene for testing purposes later\n",
    "Note: this requires establishing a reference genome that you will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_genome = '511145.12' #This is E. coli K12\n",
    "seq_dicty = {}\n",
    "# for infile_name in glob.glob('../Data/Orthologs/Order_Enterobacterales_Reference/mfastas_nt/*.mfasta'):\n",
    "# for infile_name in glob.glob('../Data/Orthologs/Order_Enterobacterales_Representative/mfastas_nt/*.mfasta'):\n",
    "for infile_name in glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/mfastas_nt/*.mfasta'):\n",
    "#     print(infile_name)\n",
    "    gene_name = infile_name.split('/')[-1].strip('.mfasta')\n",
    "    records = list(SeqIO.parse(infile_name, 'fasta'))\n",
    "    for record in records:\n",
    "        try:\n",
    "            seq_dicty[record.id][gene_name] = str(record.seq)\n",
    "        except KeyError:\n",
    "            seq_dicty[record.id] = {}\n",
    "            seq_dicty[record.id][gene_name] = str(record.seq)\n",
    "print(len(seq_dicty.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And get dicts to identify conserved amino acid positions and consensus nucleotides\n",
    "\n",
    "Please note that I'm considering an amino acid here as being \"conserved\" if 60 positions in the alignment have that same amino acid (and it's not a gap). There are 61 total positions so this just gives a little bit of flexibility to definition of conserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conservation_dicty = {}\n",
    "nt_consensus_dicty = {}\n",
    "for infile_name in glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/mfastas_nt/*.mfasta')[:]:\n",
    "    gene_name = infile_name.split('/')[-1].strip('.mfasta')\n",
    "    conservation_dicty[gene_name] = []\n",
    "    nt_consensus_dicty[gene_name] = []\n",
    "    records = list(SeqIO.parse(infile_name, 'fasta'))\n",
    "    aa_seq_lol = []\n",
    "    nt_seq_lol = []\n",
    "    for record in records:\n",
    "        aa_seq_lol.append(list(str(record.seq.translate(gap='-'))))\n",
    "        nt_seq_lol.append(list(str(record.seq)))\n",
    "    aa_seq_lol = np.array(aa_seq_lol)\n",
    "    aa_seq_lol = aa_seq_lol.T\n",
    "    for pos in aa_seq_lol:\n",
    "        counter_dict = Counter(pos)\n",
    "        if len(counter_dict.keys()) == 1 and counter_dict[list(counter_dict.keys())[0]] != '-':\n",
    "            conservation_dicty[gene_name].append('C')\n",
    "        elif len(counter_dict.keys()) == 2 and sorted(counter_dict.items(), key=lambda x: x[1])[-1][1]==60 and\\\n",
    "                sorted(counter_dict.items(), key=lambda x: x[1])[-1][0]!='-':\n",
    "            conservation_dicty[gene_name].append('C')\n",
    "        else:\n",
    "            conservation_dicty[gene_name].append('V')\n",
    "\n",
    "    nt_seq_lol = np.array(nt_seq_lol)\n",
    "    nt_seq_lol = nt_seq_lol.T\n",
    "    for pos in nt_seq_lol:\n",
    "        counter_dict = Counter(pos)\n",
    "        nt_consensus_dicty[gene_name].append(sorted(counter_dict.items(), key=lambda x: x[1])[-1][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in substitution rate datasets as separate dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty_phylop = {}\n",
    "# for infile_name in glob.glob('../Results/Order_Enterobacterales_Reference/phyloP/*.wig')[:]:\n",
    "# for infile_name in glob.glob('../Results/Order_Enterobacterales_Representative/phyloP/*.wig')[:]:\n",
    "# for infile_name in glob.glob('../Results/Order_Enterobacterales_Representative/phyloP_CONACC/*.wig')[:]:\n",
    "for infile_name in glob.glob('../Results/Order_Enterobacterales_Mixed/phyloP_CONACC/*.wig')[:]:\n",
    "    with open(infile_name, 'r') as infile:\n",
    "        tempy = infile.readlines()\n",
    "        data = [float(i) for i in tempy[1:]]\n",
    "        dicty_phylop[infile_name.split('/')[-1].strip('.wig')] = data\n",
    "print(len(dicty_phylop.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dicty_hyphy = {}\n",
    "# dicty_w = {}\n",
    "# for infile_name in glob.glob('../Results/Order_Enterobacterales_Mixed/Hyphy_JC/*.rates')[:]:\n",
    "#     with open(infile_name, 'r') as infile:\n",
    "#         tempy = infile.readlines()\n",
    "#         dicty_w[infile_name.split('/')[-1].strip('.rates')] = float(tempy[1].split(',')[2])\n",
    "#         rates = [float(i.split(',')[1]) for i in tempy[1:]]\n",
    "#         meany = np.mean(rates)\n",
    "#         dicty_hyphy[infile_name.split('/')[-1].strip('.rates')] = [i/meany for i in rates]\n",
    "# print(len(dicty_hyphy.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty_hyphy = {}\n",
    "\n",
    "for infile_name in glob.glob('../Results/Order_Enterobacterales_Mixed/Hyphy_GTR/*.site-rates.json')[:]:\n",
    "    gene_name = infile_name.split('/')[-1].strip('.site-rates.json')\n",
    "    with open(infile_name) as infile:\n",
    "        site_rate_data = json.load(infile)\n",
    "    positions = [int(i) for i in site_rate_data['Relative site rate estimates'].keys()]\n",
    "    rates = []\n",
    "    for position in range(min(positions), max(positions)+1):\n",
    "        rates.append(site_rate_data['Relative site rate estimates'][str(position)]['MLE'])\n",
    "    meany = np.mean(rates)\n",
    "    dicty_hyphy[gene_name] = [i/meany for i in rates]\n",
    "\n",
    "\n",
    "print(len(dicty_hyphy.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Trim 5' terminal gaps according to the E. coli reference sequence\n",
    "Should this be done before running the models???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean([len(i) for i in seq_dicty[base_genome].values()]))\n",
    "print(np.mean([len(i) for i in dicty_phylop.values()]))\n",
    "print(np.mean([len(i) for i in dicty_hyphy.values()]))\n",
    "\n",
    "for i, j in seq_dicty[base_genome].items():\n",
    "    if j[0:3] == '---':\n",
    "        first_bases = []\n",
    "        for base in ['A', 'T', 'G', 'C']:\n",
    "            first_bases.append(j.find(base))\n",
    "        first_base = min(first_bases)\n",
    "        \n",
    "        seq_dicty[base_genome][i] = j[first_base:]\n",
    "        \n",
    "        if i in dicty_phylop.keys():\n",
    "            dicty_phylop[i] = dicty_phylop[i][first_base:]\n",
    "        \n",
    "        if i in dicty_hyphy.keys():\n",
    "            dicty_hyphy[i] = dicty_hyphy[i][first_base:]\n",
    "\n",
    "        if i in conservation_dicty.keys():\n",
    "            conservation_dicty[i] = conservation_dicty[i][int(first_base/3):]\n",
    "                \n",
    "        if i in nt_consensus_dicty.keys():\n",
    "            nt_consensus_dicty[i] = nt_consensus_dicty[i][first_base:]\n",
    "            \n",
    "print(np.mean([len(i) for i in seq_dicty[base_genome].values()]))\n",
    "print(np.mean([len(i) for i in dicty_phylop.values()]))\n",
    "print(np.mean([len(i) for i in dicty_hyphy.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And 3' terminal gaps according to the E. coli reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean([len(i) for i in seq_dicty[base_genome].values()]))\n",
    "print(np.mean([len(i) for i in dicty_phylop.values()]))\n",
    "print(np.mean([len(i) for i in dicty_hyphy.values()]))\n",
    "\n",
    "\n",
    "for i, j in seq_dicty[base_genome].items():\n",
    "    if j[-3:] == '---':\n",
    "        last_bases = []\n",
    "        for base in ['A', 'T', 'G', 'C']:\n",
    "            last_bases.append(j[::-1].find(base))\n",
    "        last_base = min(last_bases)\n",
    "        seq_dicty[base_genome][i] = j[:len(j)-last_base]\n",
    "        if i in dicty_phylop.keys():\n",
    "            dicty_phylop[i] = dicty_phylop[i][:len(j)-last_base]\n",
    "            \n",
    "        if i in dicty_hyphy.keys():\n",
    "            dicty_hyphy[i] = dicty_hyphy[i][:len(j)-last_base]\n",
    "\n",
    "        if i in conservation_dicty.keys():\n",
    "            conservation_dicty[i] = conservation_dicty[i][:int((len(j)-last_base)/3)]\n",
    "\n",
    "        if i in nt_consensus_dicty.keys():\n",
    "            nt_consensus_dicty[i] = nt_consensus_dicty[i][:len(j)-last_base]\n",
    "print(np.mean([len(i) for i in seq_dicty[base_genome].values()]))\n",
    "print(np.mean([len(i) for i in dicty_phylop.values()]))\n",
    "print(np.mean([len(i) for i in dicty_hyphy.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####Consensus terminals?\"\n",
    "# print(np.mean([len(i) for i in seq_dicty[base_genome].values()]))\n",
    "# print(np.mean([len(i) for i in dicty_phylop.values()]))\n",
    "\n",
    "# for genome in seq_dicty.keys():\n",
    "#     longest = []\n",
    "#     for i, j in seq_dicty[genome].items():\n",
    "#         if j[0:3] == '---':\n",
    "#             first_bases = []\n",
    "#             for base in ['A', 'T', 'G', 'C']:\n",
    "#                 first_bases.append(j.find(base))\n",
    "#             first_base = min(first_bases)\n",
    "#             longest.append(first_base)\n",
    "#     strict_first = max(longest)\n",
    "#     seq_dicty[base_genome][i] = j[strict_first:]\n",
    "#     dicty_phylop[i] = dicty_phylop[i][strict_first:]\n",
    "    \n",
    "# print(np.mean([len(i) for i in seq_dicty[base_genome].values()]))\n",
    "# print(np.mean([len(i) for i in dicty_phylop.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate relationships between the metrics on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phylop = []\n",
    "for key, val in dicty_phylop.items():\n",
    "    phylop.extend(dicty_phylop[key])   \n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(phylop, 20, color='k', alpha=0.5)\n",
    "ax.set_xlabel('phyloP score')\n",
    "ax.set_ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyphy = []\n",
    "for key, val in dicty_hyphy.items():\n",
    "    hyphy.extend(dicty_hyphy[key])   \n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(hyphy, 20, color='k', alpha=0.5)\n",
    "ax.set_xlabel('hyphy (rel subs rate)')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat above averaging over genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# phylop = []\n",
    "# for key, val in dicty_phylop.items():\n",
    "#     phylop.append(np.mean(dicty_phylop[key])) \n",
    "# fig, ax = plt.subplots(figsize=(6,4))\n",
    "# ax.hist(phylop, 20, color='gray')\n",
    "# ax.set_xlabel('mean phyloP score per gene')\n",
    "# ax.set_ylabel('counts')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w = []\n",
    "# for key, val in dicty_w.items():\n",
    "#     w.append(dicty_w[key])\n",
    "# fig, ax = plt.subplots(figsize=(6,4))\n",
    "# ax.hist(w, 20, color='gray')\n",
    "# ax.set_xlabel('hyphy (w)')\n",
    "# ax.set_ylabel('counts')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable_x = []\n",
    "# variable_y = []\n",
    "# for key in seq_dicty[base_genome].keys():\n",
    "#     if key in dicty_phylop.keys() and key in dicty_hyphy.keys():\n",
    "#         variable_x.extend(dicty_hyphy[key])\n",
    "#         variable_y.extend(dicty_phylop[key])\n",
    "# #         mean_val = np.mean(dicty_phylop[key])\n",
    "# #         variable_y.extend([i/mean_val for i in dicty_phylop[key]])\n",
    "\n",
    "# print(stats.spearmanr(variable_x, variable_y))\n",
    "\n",
    "# # plt.figure()\n",
    "# # plt.semilogx(variable_x, variable_y, 'bo', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable_x = []\n",
    "# variable_y = []\n",
    "# for key in seq_dicty[base_genome].keys():\n",
    "#     if key in dicty_phylop.keys() and key in dicty_hyphy_NOT_NORMALIZED.keys():\n",
    "#         variable_x.append(np.mean(dicty_phylop[key]))\n",
    "#         variable_y.append(np.mean(dicty_hyphy_NOT_NORMALIZED[key]))\n",
    "# print(len(variable_x), len(variable_y))\n",
    "# print(stats.spearmanr(variable_x, variable_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at length and position-dependent scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivals = []\n",
    "plot_vals_phylop = []\n",
    "plot_vals_hyphy = []\n",
    "\n",
    "for i in range(150):\n",
    "    tempy = []\n",
    "    for gene_name, vals in dicty_phylop.items():\n",
    "        if len(vals) > 150:\n",
    "#             if conservation_dicty[gene_name][int(np.floor(i/3))] == 'C':\n",
    "                tempy.extend([vals[i]])\n",
    "    plot_vals_phylop.append(np.median(tempy))\n",
    "    \n",
    "    tempy = []\n",
    "    for gene_name, vals in dicty_hyphy.items():\n",
    "        if len(vals) > 150:\n",
    "#             if conservation_dicty[gene_name][int(np.floor(i/3))] == 'C':\n",
    "                tempy.extend([vals[i]])\n",
    "    plot_vals_hyphy.append(np.median(tempy))\n",
    "    \n",
    "    ivals.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivals_r = []\n",
    "plot_vals_phylop_r = []\n",
    "plot_vals_hyphy_r = []\n",
    "\n",
    "for i in range(150, 0, -1):\n",
    "    tempy = []\n",
    "    for gene_name, vals in dicty_phylop.items():\n",
    "        if len(vals) > 150:\n",
    "#             if conservation_dicty[gene_name][int(np.floor(i/3))] == 'C':\n",
    "                tempy.extend([vals[-i]])\n",
    "    plot_vals_phylop_r.append(np.median(tempy))\n",
    "    \n",
    "    tempy = []\n",
    "    for gene_name, vals in dicty_hyphy.items():\n",
    "        if len(vals) > 150:\n",
    "#             if conservation_dicty[gene_name][int(np.floor(i/3))] == 'C':\n",
    "                tempy.extend([vals[-i]])\n",
    "    plot_vals_hyphy_r.append(np.median(tempy))\n",
    "    \n",
    "    ivals_r.append(-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.plot(ivals, plot_vals_phylop)\n",
    "ax1.set_ylabel('phyloP')\n",
    "ax2 = fig.add_subplot(222, sharey=ax1)\n",
    "ax2.plot(ivals_r, plot_vals_phylop_r)\n",
    "ax3 = fig.add_subplot(223, sharex=ax1)\n",
    "ax3.plot(ivals, plot_vals_hyphy)\n",
    "ax3.set_ylabel('hyphy')\n",
    "ax3.set_xlabel('NT position')\n",
    "ax4 = fig.add_subplot(224, sharey=ax3, sharex=ax2)\n",
    "ax4.plot(ivals_r, plot_vals_hyphy_r)\n",
    "ax4.set_xlabel('NT position')\n",
    "plt.setp(ax1.get_xticklabels(), visible=False);\n",
    "plt.setp(ax2.get_xticklabels(), visible=False);\n",
    "plt.setp(ax2.get_yticklabels(), visible=False);\n",
    "plt.setp(ax4.get_yticklabels(), visible=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.plot(ivals[0::3], plot_vals_phylop[0::3], 'bo')\n",
    "ax1.plot(ivals[1::3], plot_vals_phylop[1::3], 'go')\n",
    "ax1.plot(ivals[2::3], plot_vals_phylop[2::3], 'ro')\n",
    "ax1.set_ylabel('phyloP')\n",
    "ax2 = fig.add_subplot(222, sharey=ax1)\n",
    "ax2.plot(ivals_r[0::3], plot_vals_phylop_r[0::3], 'bo')\n",
    "ax2.plot(ivals_r[1::3], plot_vals_phylop_r[1::3], 'go')\n",
    "ax2.plot(ivals_r[2::3], plot_vals_phylop_r[2::3], 'ro')\n",
    "ax3 = fig.add_subplot(223, sharex=ax1)\n",
    "ax3.plot(ivals[0::3], plot_vals_hyphy[0::3], 'bo')\n",
    "ax3.plot(ivals[1::3], plot_vals_hyphy[1::3], 'go')\n",
    "ax3.plot(ivals[2::3], plot_vals_hyphy[2::3], 'ro')\n",
    "ax3.set_ylabel('hyphy')\n",
    "ax3.set_xlabel('NT position')\n",
    "ax4 = fig.add_subplot(224, sharey=ax3, sharex=ax2)\n",
    "ax4.plot(ivals_r[0::3], plot_vals_hyphy_r[0::3], 'bo')\n",
    "ax4.plot(ivals_r[1::3], plot_vals_hyphy_r[1::3], 'go')\n",
    "ax4.plot(ivals_r[2::3], plot_vals_hyphy_r[2::3], 'ro')\n",
    "ax4.set_xlabel('NT position')\n",
    "plt.setp(ax1.get_xticklabels(), visible=False);\n",
    "plt.setp(ax2.get_xticklabels(), visible=False);\n",
    "plt.setp(ax2.get_yticklabels(), visible=False);\n",
    "plt.setp(ax4.get_yticklabels(), visible=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare 2-fold and 4-fold redundant sites, conserved and not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twofold_synon_phylop = []\n",
    "fourfold_synon_phylop = []\n",
    "\n",
    "twofold_synon_hyphy = []\n",
    "fourfold_synon_hyphy = []\n",
    "for i,j in seq_dicty[base_genome].items():\n",
    "    if i not in dicty_hyphy.keys():\n",
    "        continue\n",
    "    if i not in dicty_phylop.keys():\n",
    "        continue \n",
    "    if len(j) < 150:\n",
    "        continue\n",
    "    j_codons = [j[nt:nt+3] for nt in range(0, len(j), 3)]\n",
    "    for pos, codon in enumerate(j_codons):\n",
    "        if pos < 100:\n",
    "            continue\n",
    "        if codon == '---':\n",
    "            continue\n",
    "        if conservation_dicty[i][pos] != 'C':\n",
    "            continue\n",
    "        if codon in redundant_codons:\n",
    "            fourfold_synon_phylop.append(dicty_phylop[i][(pos*3)+2])\n",
    "            fourfold_synon_hyphy.append(dicty_hyphy[i][(pos*3)+2])\n",
    "        elif codon_to_aa_dict[codon] in ['F', 'H', 'Q', 'N', 'K', 'D', 'E']:\n",
    "            twofold_synon_phylop.append(dicty_phylop[i][(pos*3)+2])\n",
    "            twofold_synon_hyphy.append(dicty_hyphy[i][(pos*3)+2])\n",
    "            \n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.boxplot([twofold_synon_phylop, fourfold_synon_phylop]);\n",
    "ax1.set_ylabel('phyloP score')\n",
    "ax1.set_xticklabels(['2-fold\\nredundant', '4-fold\\nredundant'], rotation=0)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.boxplot([twofold_synon_hyphy, fourfold_synon_hyphy]);\n",
    "ax2.set_ylabel('hyphy score')\n",
    "ax2.set_xticklabels(['2-fold\\nredundant', '4-fold\\nredundant'], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "print('##### phyloP analysis')\n",
    "print(len(twofold_synon_phylop), len(fourfold_synon_phylop))\n",
    "print(np.mean(twofold_synon_phylop), np.mean(fourfold_synon_phylop))\n",
    "print(stats.ranksums(twofold_synon_phylop, fourfold_synon_phylop))\n",
    "\n",
    "print('##### hyphy analysis')\n",
    "print(len(twofold_synon_hyphy), len(fourfold_synon_hyphy))\n",
    "print(np.mean(twofold_synon_hyphy), np.mean(fourfold_synon_hyphy))\n",
    "print(stats.ranksums(twofold_synon_hyphy, fourfold_synon_hyphy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fourfold_synon_cons_phylop = []\n",
    "fourfold_synon_var_phylop = []\n",
    "fourfold_synon_cons_hyphy = []\n",
    "fourfold_synon_var_hyphy = []\n",
    "\n",
    "for i,j in seq_dicty[base_genome].items():\n",
    "    if i not in dicty_hyphy.keys():\n",
    "        continue\n",
    "    if i not in dicty_phylop.keys():\n",
    "        continue\n",
    "    if len(j) < 150:\n",
    "        continue\n",
    "    j_codons = [j[nt:nt+3] for nt in range(0, len(j), 3)]\n",
    "    for pos, codon in enumerate(j_codons):\n",
    "        if pos < 50:\n",
    "            continue\n",
    "        if codon == '---':\n",
    "            continue\n",
    "        if conservation_dicty[i][pos] == 'C':\n",
    "            if codon in redundant_codons:\n",
    "                fourfold_synon_cons_phylop.append(dicty_phylop[i][(pos*3)+2])\n",
    "                fourfold_synon_cons_hyphy.append(dicty_hyphy[i][(pos*3)+2])\n",
    "        elif conservation_dicty[i][pos] == 'V':\n",
    "            if codon in redundant_codons:\n",
    "                fourfold_synon_var_phylop.append(dicty_phylop[i][(pos*3)+2])\n",
    "                fourfold_synon_var_hyphy.append(dicty_hyphy[i][(pos*3)+2])\n",
    "    \n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.boxplot([fourfold_synon_cons_phylop, fourfold_synon_var_phylop]);\n",
    "ax1.set_ylabel('phyloP score')\n",
    "ax1.set_xticklabels(['Fully conserved aa', 'Variable aa'], rotation=0)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.boxplot([fourfold_synon_cons_hyphy, fourfold_synon_var_hyphy]);\n",
    "ax2.set_ylabel('hyphy score')\n",
    "ax2.set_xticklabels(['Fully conserved aa', 'Variable aa'], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "print('##### phyloP analysis')\n",
    "print(len(fourfold_synon_cons_phylop), len(fourfold_synon_var_phylop))\n",
    "print(\"Category Means:\", np.mean(fourfold_synon_cons_phylop), np.mean(fourfold_synon_var_phylop))\n",
    "print(\"Category Medians:\", np.median(fourfold_synon_cons_phylop), np.median(fourfold_synon_var_phylop))\n",
    "\n",
    "print(stats.ranksums(fourfold_synon_cons_phylop, fourfold_synon_var_phylop))\n",
    "\n",
    "print('##### hyphy analysis')\n",
    "print(len(fourfold_synon_cons_hyphy), len(fourfold_synon_var_hyphy))\n",
    "print(\"Category Means:\", np.mean(fourfold_synon_cons_hyphy), np.mean(fourfold_synon_var_hyphy))\n",
    "print(\"Category Medians:\", np.median(fourfold_synon_cons_hyphy), np.median(fourfold_synon_var_hyphy))\n",
    "print(stats.ranksums(fourfold_synon_cons_hyphy, fourfold_synon_var_hyphy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a SD threshold strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/json-energyRef-CCUCCU.txt') as infile:\n",
    "    fragment_energy_dict = json.load(infile)\n",
    "asd_seq = 'CCTCCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_utrs = []\n",
    "include = 20\n",
    "genome = list(SeqIO.parse('/Users/adamhockenberry/Projects/2017/Genome_database/Data/GBFs/511145.12.PATRIC.gbf', 'genbank'))\n",
    "for record in genome:\n",
    "    for feature in record.features[:]:\n",
    "        if feature.type == 'CDS':\n",
    "            if feature.location.strand == 1:\n",
    "                real_utrs.append(record.seq[feature.location.start-include:feature.location.start])\n",
    "            elif feature.location.strand == -1:\n",
    "                real_utrs.append(record.seq[feature.location.end:feature.location.end+include].reverse_complement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomizations = 1\n",
    "real_utrs = [str(i) for i in real_utrs]\n",
    "strongest_real = []\n",
    "strongest_fake = []\n",
    "strongest_fake_dict = {}\n",
    "for randomization in range(randomizations):\n",
    "    strongest_fake_dict[randomization] = []\n",
    "\n",
    "\n",
    "for utr in real_utrs[:]:\n",
    "    energy_list = []\n",
    "    for i in range(0, len(utr)-len(asd_seq)-4):\n",
    "        fragment = utr[i:i+len(asd_seq)]\n",
    "        energy = fragment_energy_dict[fragment.replace('T', 'U')]\n",
    "        energy_list.append(energy)\n",
    "    strongest_real.append(min(energy_list))\n",
    "    \n",
    "    for randomization in range(randomizations):\n",
    "        energy_list = []\n",
    "        utr_rand = np.array(list(utr))\n",
    "        np.random.shuffle(utr_rand)\n",
    "        utr_rand = ''.join(list(utr_rand))\n",
    "        for i in range(0, len(utr_rand)-len(asd_seq)-4):\n",
    "            fragment = utr_rand[i:i+len(asd_seq)]\n",
    "            energy = fragment_energy_dict[fragment.replace('T', 'U')]\n",
    "            energy_list.append(energy)\n",
    "        strongest_fake.append(min(energy_list))\n",
    "        strongest_fake_dict[randomization].append(min(energy_list))\n",
    "print(len(strongest_real))\n",
    "print(len(strongest_fake))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(strongest_fake, 60, normed=True, alpha=0.5, color='gray')\n",
    "plt.hist(strongest_real, 60, normed=True, alpha=0.5)\n",
    "plt.axvline(-4.0, c='r')\n",
    "# plt.axvline(-3.75, c='r', alpha=0.5)\n",
    "plt.axvline(-5.5, c='r', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testy = []\n",
    "for threshold in np.arange(0, -10, -0.1):\n",
    "    print(threshold)\n",
    "    actual = len([i for i in strongest_real if i < threshold])\n",
    "    randos = [len([i for i in k if i < threshold]) for j,k in strongest_fake_dict.items()]\n",
    "    print(actual, np.mean(randos))\n",
    "    testy.append((actual-np.mean(randos)))\n",
    "#     testy.append((actual-np.mean(randos))/np.std(randos))\n",
    "    if actual > max(randos):\n",
    "        print('hereeeeeeeee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(0, -10, -0.1), testy)\n",
    "plt.axvline(-4.5)\n",
    "plt.axvline(-4.0)\n",
    "plt.axvline(-3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually dig into data to test for conservation of individual X-mers\n",
    "Still trying to decide on the best strategy. My current thinking is to look ONLY at 4-fold redundant codon sites that are within a strong-ish aSD binding site and for each one compare the conservation at that site to the same synonymous codon somewhere else in the same gene. With a list of these, can compare whether there is any conservation difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive control data. Find genes that have another gene directly 3' of them which are thus likely to contain a real SD sequence in their 3' terminus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preceding_genes = []\n",
    "starts_positive_strand = []\n",
    "starts_negative_strand = []\n",
    "genome = list(SeqIO.parse('/Users/adamhockenberry/Projects/2017/Genome_database/Data/GBFs/511145.12.PATRIC.gbf', 'genbank'))\n",
    "for record in genome:\n",
    "    for feature in record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            if feature.location.strand == 1:\n",
    "                starts_positive_strand.append(feature.location.start)\n",
    "            elif feature.location.strand == -1:\n",
    "                starts_negative_strand.append(feature.location.end)\n",
    "for i,j in enumerate(starts_positive_strand):\n",
    "    starts_positive_strand[i] = list(range(j-20,j+10,1))\n",
    "for i,j in enumerate(starts_negative_strand):\n",
    "    starts_negative_strand[i] = list(range(j-10,j+20,1))\n",
    "for record in genome:\n",
    "    for feature in record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            if feature.location.strand == 1:\n",
    "                end = feature.location.end\n",
    "                for i in starts_positive_strand:\n",
    "                    if end in i:\n",
    "                        preceding_genes.append(feature.qualifiers['locus_tag'][0])\n",
    "            elif feature.location.strand == -1:\n",
    "                end = feature.location.start\n",
    "                for i in starts_negative_strand:\n",
    "                    if end in i:\n",
    "                        preceding_genes.append(feature.qualifiers['locus_tag'][0])\n",
    "                        \n",
    "preceding_genes = [i for i in seq_dicty[base_genome].keys() if i in preceding_genes]\n",
    "not_preceding_genes = [i for i in seq_dicty[base_genome].keys() if i not in preceding_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(preceding_genes), len(not_preceding_genes), len(seq_dicty[base_genome].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing conservation of a particular 4-fold redundant position that is within a strong binding sequence to a randomly chosen identical 4-fold redundant codon elsewhere in the sequence\n",
    "Note I'm currently looking at a 6nt aSD sequence and only considering 4-fold redundant codons in positions 2,3,4, or 5. I'm also taking care not to double count any one position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sd_sites(nt_sequence, asd_seq, threshold, fragment_energy_dict, upper_threshold=-20, min_position=100, max_position=-50, three_prime_analysis=False):\n",
    "    codon_list = [nt_sequence[nt:nt+3] for nt in range(0, len(nt_sequence), 3)]\n",
    "    energy_list = []\n",
    "    for i in range(0, len(nt_sequence)-len(asd_seq)):\n",
    "        fragment = nt_sequence[i:i+len(asd_seq)]\n",
    "        if fragment.count('-') == 0:\n",
    "            energy = fragment_energy_dict[fragment.replace('T', 'U')]\n",
    "            energy_list.append(energy)\n",
    "        else:\n",
    "            energy_list.append(np.nan)\n",
    "    #######This gets all positions below the given threshold\n",
    "    sd_positions_all_nts = [list(range(i, i+len(asd_seq))) for i,j in enumerate(energy_list) if j < threshold]\n",
    "    sd_positions_all_nts = [item for sublist in sd_positions_all_nts for item in sublist]\n",
    "    sd_positions_all_nts = list(set(sd_positions_all_nts))\n",
    "    \n",
    "    #######This gets all \"start\" position within the threshold range. Subtle but important difference\n",
    "    if three_prime_analysis:\n",
    "        sd_positions_start = np.array([i for i,j in enumerate(energy_list) if upper_threshold < j and j < threshold and i > len(nt_sequence)-50])\n",
    "    else:\n",
    "        sd_positions_start = np.array([i for i,j in enumerate(energy_list) if upper_threshold < j and j < threshold and i > min_position and i < len(nt_sequence)+max_position])\n",
    "    \n",
    "    np.random.shuffle(sd_positions_start) #So I'm not always analyzing the 5' ones every single time\n",
    "    return sd_positions_all_nts, sd_positions_start, energy_list, codon_list\n",
    "\n",
    "def get_control_sites_codon(nt_sequence, codon_list, sd_positions_all_nts, analyzed_positions, codon, min_position=100, max_position=-50):\n",
    "    control_sites = [site*3+2 for site, x in enumerate(codon_list) if x == codon]\n",
    "    control_sites = [site for site in control_sites if site > min_position and site < len(nt_sequence)+max_position]\n",
    "    control_sites = [site for site in control_sites if site not in sd_positions_all_nts]\n",
    "    control_sites = [site for site in control_sites if site not in analyzed_positions]\n",
    "    return control_sites\n",
    "\n",
    "def get_control_sites_tri_nt(nt_sequence, codon_list, sd_positions_all_nts, analyzed_positions, tri_nt, redundant_codons, min_position=100, max_position=-50):\n",
    "    control_sites = [m.start()+1 for m in re.finditer(tri_nt, nt_sequence)]\n",
    "    control_sites = [site for site in control_sites if site > min_position and site < len(nt_sequence)+max_position]\n",
    "    control_sites = [site for site in control_sites if site%3 == 2]\n",
    "    control_sites = [site for site in control_sites if nt_sequence[site-2:site+1] in redundant_codons]\n",
    "    control_sites = [site for site in control_sites if site not in sd_positions_all_nts]\n",
    "    control_sites = [site for site in control_sites if site not in analyzed_positions]\n",
    "    return control_sites\n",
    "\n",
    "def get_possible_energies(fragment, codon, all_codons, modifier, fragment_energy_dict):\n",
    "    possible_energies = []\n",
    "    for possible_codon in all_codons:\n",
    "        if possible_codon != codon:\n",
    "            if modifier == 2:\n",
    "                possible_fragment = possible_codon + fragment[-3:]\n",
    "            elif modifier == 3:\n",
    "                possible_fragment = fragment[0] + possible_codon + fragment[-2:]\n",
    "            elif modifier == 1:\n",
    "                possible_fragment = possible_codon[-2:] + fragment[-4:]\n",
    "            elif modifier == 4:\n",
    "                possible_fragment = fragment[0:2] + possible_codon + fragment[-1]\n",
    "            assert len(possible_fragment) == 6\n",
    "            possible_energies.append(fragment_energy_dict[possible_fragment.replace('T', 'U')])\n",
    "    return possible_energies\n",
    "\n",
    "\n",
    "def paired_nt_analysis(dicty_to_analyze,\\\n",
    "                      genome_seq_dicty,\\\n",
    "                      fragment_energy_dict,\\\n",
    "                      asd_seq,\\\n",
    "                      conservation_dicty,\\\n",
    "                      redundant_codons=redundant_codons,\\\n",
    "                      threshold=-4.5,\\\n",
    "                      upper_threshold=-20,\\\n",
    "                      min_position=100,\\\n",
    "                      max_position=-50,\\\n",
    "                      subset_names=False,\\\n",
    "                      randomization=False,\\\n",
    "                      only_conserved_aa=False,\\\n",
    "                      three_prime_analysis=False,\\\n",
    "                      internal_control='',\n",
    "                      nt_strength_restriction=''):\n",
    "    sds = []\n",
    "    others = []\n",
    "    for gene_name, seq in list(genome_seq_dicty.items())[:]:\n",
    "\n",
    "        analyzed_positions = []\n",
    "\n",
    "        if gene_name not in dicty_to_analyze.keys():\n",
    "            continue\n",
    "        if subset_names:\n",
    "            if gene_name not in subset_names:\n",
    "                continue\n",
    "        ##################################################################################################\n",
    "        ###GET LOCATIONS OF ALL SD-LIKE SEQUENCES THAT I MIGHT WANT TO ANALYZE        \n",
    "        sd_positions_all_nts, sd_positions_start, energy_list, codon_list =\\\n",
    "                        get_sd_sites(seq, asd_seq, threshold, fragment_energy_dict,\\\n",
    "                                     upper_threshold=upper_threshold, min_position=min_position,\\\n",
    "                                     max_position=max_position, three_prime_analysis=three_prime_analysis)\n",
    "        \n",
    "        for i in sd_positions_start:\n",
    "            energy = energy_list[i]\n",
    "            modifiers = []\n",
    "            if i%3 == 0:\n",
    "                modifiers = [2]\n",
    "            elif i%3 == 2:\n",
    "                modifiers = [3]\n",
    "            elif i%3 == 1:\n",
    "                modifiers = [1,4]\n",
    "            for modifier in modifiers:\n",
    "                if only_conserved_aa == True:\n",
    "                    if conservation_dicty[gene_name][int(np.floor((i+modifier)/3.))] != 'C':\n",
    "                        continue\n",
    "#                     if conservation_dicty[gene_name][int(np.floor((i+modifier+3)/3.))] != 'C':\n",
    "#                         continue\n",
    "#                     if conservation_dicty[gene_name][int(np.floor((i+modifier-3)/3.))] != 'C':\n",
    "#                         continue\n",
    "                codon = seq[i+modifier-2:i+modifier+1]\n",
    "                tri_nt = seq[i+modifier-1:i+modifier+2]\n",
    "                if codon in redundant_codons:\n",
    "                    ##################################################################################################\n",
    "                    ###RUN A FILTER ACCORDING TO WHETHER I ONLY WANT TO SELECT STRONGEST OR WEAKEST POSSIBLE SEQUENCES\n",
    "                    if nt_strength_restriction == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        fragment = genome_seq_dicty[gene_name][i:i+len(asd_seq)]\n",
    "                        all_codons = aa_to_codon_dict[codon_to_aa_dict[codon]]\n",
    "                        possible_energies = get_possible_energies(fragment, codon, all_codons, modifier, fragment_energy_dict)\n",
    "                        if nt_strength_restriction == 'CURRENT_IS_STRONGEST':\n",
    "                            if energy > min(possible_energies):\n",
    "                                continue\n",
    "                        elif nt_strength_restriction=='CURRENT_IS_WEAKEST':\n",
    "                            if energy < max(possible_energies):\n",
    "                                continue\n",
    "                        else:\n",
    "                            print('YOU DID NOT PROPERLY SPECIFY THE NT_STRENGTH_RESTRICTION VARIABLE')\n",
    "                            break\n",
    "                    ##################################################################################################\n",
    "                    ###GET CONTROL SITES ACCORDING TO EITHER OF TWO DIFFERENT NULL MODELS\n",
    "                    if internal_control == 'CODON':\n",
    "                        control_sites =\\\n",
    "                            get_control_sites_codon(seq, codon_list, sd_positions_all_nts, analyzed_positions, codon,\\\n",
    "                                                   min_position=min_position, max_position=max_position)\n",
    "                    elif internal_control == 'TRINT':\n",
    "                        control_sites =\\\n",
    "                            get_control_sites_tri_nt(seq, codon_list, sd_positions_all_nts, analyzed_positions, tri_nt, redundant_codons,\\\n",
    "                                                    min_position=min_position, max_position=max_position)\n",
    "                    else:\n",
    "                        print(\"YOU DID NOT PROPERLY SPECIFY A CONTROL METHOD\")\n",
    "                        break\n",
    "                    ##################################################################################################\n",
    "                    ###DECIDE WHETHER TO LIMIT ACCORDING TO CONSERVATION OF THE AMINO ACID \n",
    "                    if only_conserved_aa == True:\n",
    "                        control_sites = [site for site in control_sites if conservation_dicty[gene_name][int(np.floor(site/3.))] == 'C']\n",
    "#                         control_sites = [site for site in control_sites if conservation_dicty[gene_name][int(np.floor((site+3)/3.))] == 'C']\n",
    "#                         control_sites = [site for site in control_sites if conservation_dicty[gene_name][int(np.floor((site-3)/3.))] == 'C']\n",
    "\n",
    "                    ##################################################################################################\n",
    "                    ###IF ALL LOOKS WELL CHOOSE A CONTROL AND GO FORWARD WITH ANALYSIS\n",
    "                    if len(control_sites) > 0 and i+modifier not in analyzed_positions:\n",
    "                        choice = random.choice(control_sites)\n",
    "                        if randomization==True:\n",
    "                            if np.random.choice(['H', 'T']) == 'H': #Heads or tails coinflip for random assignment. Smiley face.\n",
    "                                sds.append(dicty_to_analyze[gene_name][i+modifier])\n",
    "                                others.append(dicty_to_analyze[gene_name][choice])\n",
    "                            else:\n",
    "                                sds.append(dicty_to_analyze[gene_name][choice])\n",
    "                                others.append(dicty_to_analyze[gene_name][i+modifier])\n",
    "                        else:\n",
    "                            sds.append(dicty_to_analyze[gene_name][i+modifier])\n",
    "                            others.append(dicty_to_analyze[gene_name][choice])\n",
    "                                                    \n",
    "                        analyzed_positions.append(i+modifier)\n",
    "                        analyzed_positions.append(choice)\n",
    "                        #######################################################################\n",
    "                        ###Fail safe to make sure I chose the right codons and context controls\n",
    "                        if internal_control == 'CODON':\n",
    "                            assert seq_dicty[base_genome][gene_name][i+modifier-2:i+modifier+1] == seq_dicty[base_genome][gene_name][choice-2:choice+1]\n",
    "                        if internal_control == 'TRINT':\n",
    "                            assert seq_dicty[base_genome][gene_name][i+modifier-1:i+modifier+2] == seq_dicty[base_genome][gene_name][choice-1:choice+2]\n",
    "\n",
    "    return sds, others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_nt_analysis(dicty_to_analyze,\\\n",
    "                      genome_seq_dicty,\\\n",
    "                      fragment_energy_dict,\\\n",
    "                      asd_seq,\\\n",
    "                      conservation_dicty,\\\n",
    "                      redundant_codons=redundant_codons,\\\n",
    "                      threshold=-4.5,\\\n",
    "                      subset_names=False,\\\n",
    "                      randomization=False,\\\n",
    "                      only_conserved_aa=False,\\\n",
    "                      three_prime_analysis=False):\n",
    "    sds = []\n",
    "    control_codon = []\n",
    "    control_tri_nt = []\n",
    "    \n",
    "    for gene_name, seq in list(genome_seq_dicty.items())[:]:\n",
    "        analyzed_positions = []\n",
    "\n",
    "\n",
    "        if gene_name not in dicty_to_analyze.keys():\n",
    "            continue\n",
    "        if subset_names:\n",
    "            if gene_name not in subset_names:\n",
    "                continue\n",
    "\n",
    "\n",
    "                \n",
    "        sd_positions_all_nts, sd_positions_start, energy_list, codon_list =\\\n",
    "                        get_sd_sites(seq, asd_seq, threshold, fragment_energy_dict, min_position=100, max_position=-50, three_prime_analysis=three_prime_analysis)\n",
    "        possible_codons = []\n",
    "        possible_tri_nts = []\n",
    "        for i in sd_positions_start:\n",
    "            energy = energy_list[i]\n",
    "            modifiers = []\n",
    "            if i%3 == 0:\n",
    "                modifiers = [2]\n",
    "            elif i%3 == 2:\n",
    "                modifiers = [3]\n",
    "            elif i%3 == 1:\n",
    "                modifiers = [1,4]\n",
    "            for modifier in modifiers:\n",
    "                if only_conserved_aa == True:\n",
    "                    if conservation_dicty[gene_name][int(np.floor((i+modifier)/3.))] != 'C':\n",
    "                        continue\n",
    "#                     if conservation_dicty[gene_name][int(np.floor((i+modifier+3)/3.))] != 'C':\n",
    "#                         continue\n",
    "#                     if conservation_dicty[gene_name][int(np.floor((i+modifier-3)/3.))] != 'C':\n",
    "#                         continue\n",
    "                codon = seq[i+modifier-2:i+modifier+1]\n",
    "                tri_nt = seq[i+modifier-1:i+modifier+2]\n",
    "                if codon in redundant_codons and i+modifier not in analyzed_positions:\n",
    "                    sds.append(dicty_to_analyze[gene_name][i+modifier])\n",
    "                    possible_codons.append(codon)\n",
    "                    possible_tri_nts.append(tri_nt)\n",
    "                    analyzed_positions.append(i+modifier)\n",
    "    \n",
    "        possible_codons = list(set(possible_codons))\n",
    "        for codon in possible_codons:\n",
    "            locs = [site*3+2 for site, x in enumerate(codon_list) if x == codon]\n",
    "            locs = [site for site in locs if site not in analyzed_positions and site > 100 and site < len(seq)-50]\n",
    "            if only_conserved_aa == True:\n",
    "                locs = [site for site in locs if conservation_dicty[gene_name][int(np.floor(site/3.))] == 'C']\n",
    "#                 locs = [site for site in locs if conservation_dicty[gene_name][int(np.floor((site+3)/3.))] == 'C']\n",
    "#                 locs = [site for site in locs if conservation_dicty[gene_name][int(np.floor((site-3)/3.))] == 'C']\n",
    "            control_codon.extend([dicty_to_analyze[gene_name][site] for site in locs])\n",
    "        \n",
    "        possible_tri_nts = list(set(possible_tri_nts))\n",
    "        for tri_nt in possible_tri_nts:\n",
    "            locs = [m.start()+1 for m in re.finditer(tri_nt, seq)]\n",
    "            locs = [site for site in locs if site > 100 and site < len(seq)-50]\n",
    "            locs = [site for site in locs if site%3 == 2]\n",
    "            locs = [site for site in locs if seq[site-2:site+1] in redundant_codons]\n",
    "            if only_conserved_aa == True:\n",
    "                locs = [site for site in locs if conservation_dicty[gene_name][int(np.floor(site/3.))] == 'C']\n",
    "#                 locs = [site for site in locs if conservation_dicty[gene_name][int(np.floor((site+3)/3.))] == 'C']\n",
    "#                 locs = [site for site in locs if conservation_dicty[gene_name][int(np.floor((site-3)/3.))] == 'C']\n",
    "\n",
    "            control_tri_nt.extend([dicty_to_analyze[gene_name][site] for site in locs])\n",
    "        \n",
    "    return sds, control_codon, control_tri_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty_to_analyze = dicty_hyphy\n",
    "threshold=-4.5\n",
    "upper_threshold=-20\n",
    "subset_names=False\n",
    "only_conserved_aa=False\n",
    "three_prime_analysis=False\n",
    "controls=('CODON', 'TRINT')\n",
    "nt_strength_restriction=''\n",
    "# nt_strength_restriction='CURRENT_IS_STRONGEST'\n",
    "\n",
    "with open('../Data/json-energyRef-CCUCCU.txt') as infile:\n",
    "    fragment_energy_dict = json.load(infile)\n",
    "asd_seq = 'CCUCCU'\n",
    "\n",
    "\n",
    "file_name_modifiers = '{}_threshold={}_Conserved={}_ThreePrime={}'.format('hyphy', threshold, only_conserved_aa, three_prime_analysis)\n",
    "\n",
    "\n",
    "actual_ratios_codon = []\n",
    "shuffled_ratios_codon = []\n",
    "actual_ratios_trint = []\n",
    "shuffled_ratios_trint = []\n",
    "for i in range(20):\n",
    "    print('#####{}'.format(i))\n",
    "    sds, others = paired_nt_analysis(dicty_to_analyze,\\\n",
    "                                     seq_dicty[base_genome],\\\n",
    "                                     fragment_energy_dict,\\\n",
    "                                     asd_seq,\\\n",
    "                                     conservation_dicty,\\\n",
    "                                     threshold=threshold,\\\n",
    "                                     upper_threshold=upper_threshold,\\\n",
    "                                     randomization=False,\\\n",
    "                                     subset_names=subset_names,\\\n",
    "                                     only_conserved_aa=only_conserved_aa,\\\n",
    "                                     three_prime_analysis=three_prime_analysis,\\\n",
    "                                     internal_control=controls[0],\\\n",
    "                                     nt_strength_restriction=nt_strength_restriction)\n",
    "    actual_ratios_codon.append(np.mean(sds)/np.mean(others))\n",
    "    print('Lengths:{}, {}, Means:{}, {}, Ratio:{}'.format(len(sds), len(others), np.mean(sds), np.mean(others), np.mean(sds)/np.mean(others)))\n",
    "    sds, others = paired_nt_analysis(dicty_to_analyze,\\\n",
    "                                     seq_dicty[base_genome],\\\n",
    "                                     fragment_energy_dict,\\\n",
    "                                     asd_seq,\\\n",
    "                                     conservation_dicty,\\\n",
    "                                     threshold=threshold,\\\n",
    "                                     upper_threshold=upper_threshold,\\\n",
    "                                     randomization=True,\\\n",
    "                                     subset_names=subset_names,\\\n",
    "                                     only_conserved_aa=only_conserved_aa,\\\n",
    "                                     three_prime_analysis=three_prime_analysis,\\\n",
    "                                     internal_control=controls[0],\\\n",
    "                                     nt_strength_restriction=nt_strength_restriction)\n",
    "    shuffled_ratios_codon.append(np.mean(sds)/np.mean(others))\n",
    "    \n",
    "    sds, others = paired_nt_analysis(dicty_to_analyze,\\\n",
    "                                     seq_dicty[base_genome],\\\n",
    "                                     fragment_energy_dict,\\\n",
    "                                     asd_seq,\\\n",
    "                                     conservation_dicty,\\\n",
    "                                     threshold=threshold,\\\n",
    "                                     upper_threshold=upper_threshold,\\\n",
    "                                     randomization=False,\\\n",
    "                                     subset_names=subset_names,\\\n",
    "                                     only_conserved_aa=only_conserved_aa,\\\n",
    "                                     three_prime_analysis=three_prime_analysis,\\\n",
    "                                     internal_control=controls[1],\\\n",
    "                                     nt_strength_restriction=nt_strength_restriction)\n",
    "    actual_ratios_trint.append(np.mean(sds)/np.mean(others))\n",
    "    print('Lengths:{}, {}, Means:{}, {}, Ratio:{}'.format(len(sds), len(others), np.mean(sds), np.mean(others), np.mean(sds)/np.mean(others)))\n",
    "    sds, others = paired_nt_analysis(dicty_to_analyze,\\\n",
    "                                     seq_dicty[base_genome],\\\n",
    "                                     fragment_energy_dict,\\\n",
    "                                     asd_seq,\\\n",
    "                                     conservation_dicty,\\\n",
    "                                     threshold=threshold,\\\n",
    "                                     upper_threshold=upper_threshold,\\\n",
    "                                     randomization=True,\\\n",
    "                                     subset_names=subset_names,\\\n",
    "                                     only_conserved_aa=only_conserved_aa,\\\n",
    "                                     three_prime_analysis=three_prime_analysis,\\\n",
    "                                     internal_control=controls[1],\\\n",
    "                                     nt_strength_restriction=nt_strength_restriction)\n",
    "    shuffled_ratios_trint.append(np.mean(sds)/np.mean(others))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfA = pd.DataFrame({'Actual_rats_codon':actual_ratios_codon})\n",
    "dfB = pd.DataFrame({'Shuffled_rats_codon':shuffled_ratios_codon})\n",
    "dfC = pd.DataFrame({'Actual_rats_trint':actual_ratios_trint})\n",
    "dfD = pd.DataFrame({'Shuffled_rats_trint':shuffled_ratios_trint})\n",
    "df = pd.concat([dfA[['Actual_rats_codon']],dfB[['Shuffled_rats_codon']],\\\n",
    "               dfC[['Actual_rats_trint']],dfD[['Shuffled_rats_trint']]], axis=1)\n",
    "df.to_csv('../Results/temp_df_{}_ratios.csv'.format(file_name_modifiers), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unpaired analysis (for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sds, all_others_codon, all_others_tri_nt = all_nt_analysis(dicty_to_analyze,\\\n",
    "                                 seq_dicty[base_genome],\\\n",
    "                                 fragment_energy_dict,\\\n",
    "                                 asd_seq,\\\n",
    "                                 conservation_dicty,\\\n",
    "                                 threshold=threshold,\\\n",
    "                                 randomization=False,\\\n",
    "                                 subset_names=subset_names,\\\n",
    "                                 only_conserved_aa=only_conserved_aa,\\\n",
    "                                 three_prime_analysis=three_prime_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(all_sds), len(all_others_codon), len(all_others_tri_nt))\n",
    "\n",
    "\n",
    "dfA = pd.DataFrame({'SD-like':all_sds})\n",
    "dfB = pd.DataFrame({'Control\\n(codon)':all_others_codon})\n",
    "dfC = pd.DataFrame({'Control\\n(context)':all_others_tri_nt})\n",
    "\n",
    "df = pd.concat([dfA[['SD-like']],dfB[['Control\\n(codon)']], dfC[['Control\\n(context)']]], axis=1)\n",
    "df.to_csv('../Results/temp_df_{}.csv'.format(file_name_modifiers), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/foldingFromPNAS_v2.csv')\n",
    "df['bNumber'] = ''\n",
    "df['patricNumber'] = ''\n",
    "print(len(df.index))\n",
    "\n",
    "for index in df.index:\n",
    "    names = df.loc[index]['Gene names'].split(' ')\n",
    "    for name in names:\n",
    "        if name in reference_name_dict.keys():\n",
    "            df.set_value(index, 'bNumber', name)\n",
    "            try:\n",
    "                df.set_value(index, 'patricNumber', reference_name_dict[name])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "df = df[df['patricNumber'] != '']\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose whether to stratify the data according to Lm\n",
    "...9 billion dof here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['Lm (residues)'].isnull() == False]\n",
    "# df = df[(df['Lm (residues)'] > 0) & (df['Lm (residues)'] <= 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anywayyy, domain_dict will specify what regions in what proteins I want to actually consider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Domain_beg_nt'] = int()\n",
    "df['Domain_end_nt'] = int()\n",
    "for index in df.index:\n",
    "    domain_beg, domain_end = df.loc[index]['Codon range of domain'].split('-')\n",
    "    df.set_value(index, 'Domain_beg_nt', int(domain_beg)*3)\n",
    "    df.set_value(index, 'Domain_end_nt', int(domain_end)*3)\n",
    "\n",
    "    \n",
    "df['Domain_beg_in_patric'] = int()\n",
    "df['Domain_end_in_patric'] = int()\n",
    "for index in df.index:    \n",
    "    ref_seq_beg = ref_genome_seq_ref_dict[df.loc[index]['bNumber']][int(df.loc[index]['Domain_beg_nt']):int(df.loc[index]['Domain_beg_nt'])+100]\n",
    "    ref_seq_end = ref_genome_seq_ref_dict[df.loc[index]['bNumber']][int(df.loc[index]['Domain_end_nt'])-100:int(df.loc[index]['Domain_end_nt'])]\n",
    "    df.set_value(index, 'Domain_beg_in_patric', ref_genome_seq_patric_dict[df.loc[index]['patricNumber']].find(ref_seq_beg))\n",
    "    df.set_value(index, 'Domain_end_in_patric', ref_genome_seq_patric_dict[df.loc[index]['patricNumber']].find(ref_seq_end) + 100)\n",
    "\n",
    "\n",
    "domain_dicts = {}\n",
    "for index in df.index:\n",
    "    try:\n",
    "        domain_dicts[df.loc[index]['patricNumber']].append(df.loc[index]['Domain_end_in_patric'])\n",
    "    except:\n",
    "        domain_dicts[df.loc[index]['patricNumber']] = [df.loc[index]['Domain_end_in_patric']]\n",
    "        \n",
    "for i,j in domain_dicts.items():\n",
    "    tempy = []\n",
    "    for loc in j:\n",
    "#         tempy.extend(list(range(loc+60, loc+150))) #####IMPORTANT\n",
    "        tempy.extend(list(range(loc-150, loc))) #####IMPORTANT\n",
    "    domain_dicts[i] = tempy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../Data/json-energyRef-CCUCCU.txt') as infile:\n",
    "    energy_dict = json.load(infile)\n",
    "asd = 'CCTCCT'\n",
    "threshold = -4.5\n",
    "\n",
    "sds = []\n",
    "others = []\n",
    "for gene_name, seq in list(seq_dicty[base_genome].items())[:]:\n",
    "    if gene_name not in domain_dicts:\n",
    "        continue\n",
    "    if gene_name not in dicty_hyphy.keys():\n",
    "        continue\n",
    "    codon_list = [seq[nt:nt+3] for nt in range(0, len(seq), 3)]\n",
    "    energy_list = []\n",
    "    for i in range(0, len(seq)-len(asd)):\n",
    "        fragment = seq[i:i+len(asd)]\n",
    "        if fragment.count('-') == 0:\n",
    "            energy = energy_dict[fragment.replace('T', 'U')]\n",
    "            energy_list.append(energy)\n",
    "        else:\n",
    "            energy_list.append(np.nan)\n",
    "    analyzed_positions = []\n",
    "    sd_positions = [list(range(i, i+6)) for i,j in enumerate(energy_list) if j < threshold]\n",
    "    sd_positions = [item for sublist in sd_positions for item in sublist]\n",
    "    sd_positions = list(set(sd_positions))\n",
    "    for i, energy in enumerate(energy_list):\n",
    "        if i in domain_dicts[gene_name]:\n",
    "                if energy < threshold and i > 100 and i < len(seq)-50:\n",
    "#                 if energy < threshold and i > 100 and i < len(seq)-50 and gene_name in expression_subset:\n",
    "#                 if energy < threshold and i > 50 and i < len(seq)-50 and gene_name in long_genes:\n",
    "#                 if energy < threshold and i > len(seq)-50 and gene_name in preceding_genes:\n",
    "#                 if energy < threshold and i > len(seq)-50 and gene_name not in preceding_genes:\n",
    "                    if i%3 == 0:\n",
    "                        modifiers = [2]\n",
    "                    elif i%3 == 2:\n",
    "                        modifiers = [3]\n",
    "                    elif i%3 == 1:\n",
    "                        modifiers = [1,4]\n",
    "                    for modifier in modifiers:\n",
    "                        codon = seq[i+modifier-2:i+modifier+1]\n",
    "                        if codon in redundant_codons:\n",
    "                            control_sites = [j*3+2 for j, x in enumerate(codon_list) if x == codon]\n",
    "                            control_sites = [j for j in control_sites if j not in sd_positions and j > 100 and j < len(seq)-50]\n",
    "                            if len(control_sites) > 0 and i+modifier not in analyzed_positions:\n",
    "                                sds.append(dicty_hyphy[gene_name][i+modifier])\n",
    "                                others.append(dicty_hyphy[gene_name][random.choice(control_sites)])\n",
    "                                analyzed_positions.append(i+modifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Length of my data: {} and {}'.format(len(sds),len(others)))\n",
    "print('Means of each category SD ({}) and non ({})'.format(np.mean(sds), np.mean(others)))\n",
    "print('Statistical test {}'.format(stats.wilcoxon(sds, others)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.hist(np.array(sds)-np.array(others), 40, alpha=0.8);\n",
    "ax.set_xlabel('Difference\\n <---SD less conserved // SD more conserved--->');\n",
    "ax.set_ylabel('counts');\n",
    "ax.axvline(0, c='r', linewidth=2)\n",
    "ax.axvline(np.mean(np.array(sds)-np.array(others)), c='c', linewidth=2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.violinplot([np.array(sds), np.array(others)], points=50, widths=0.5, showextrema=False);\n",
    "ax.set_xticklabels(['', 'SD sites', '', 'Controls'])\n",
    "ax.set_ylabel('phylop conservation score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Re-investigate that whole hypothesis (from my prior initial work) whereby SD sites were (maybe?) enriched after domain ends\n",
    "\n",
    "## NOTE: this section needs re-done once I've settled more on the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_total = []\n",
    "# for index in df.index:\n",
    "# for index in df[df['Lm (residues)'].isnull() == False].index:\n",
    "# for index in df[(df['Lm (residues)'] > 0)].index:\n",
    "for index in df[(df['Lm (residues)'] > 5) & (df['Lm (residues)'] < 30)].index:\n",
    "    domain_beg, domain_end = df.loc[index]['Codon range of domain'].split('-')\n",
    "    domain_beg = int(domain_beg)*3\n",
    "    domain_end = int(domain_end)*3\n",
    "    if domain_end-domain_beg > 105 and domain_end < len(ref_genome_seq_ref_dict[df.loc[index]['bNumber']]) - 100:\n",
    "        total_seq = str(ref_genome_seq_ref_dict[df.loc[index]['bNumber']][domain_end-100:domain_end+100]).replace('T', 'U')\n",
    "        matrix_total.append([energy_dict[total_seq[i:i+6]] for i in range(0, len(total_seq)-6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.shape(matrix_total))\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(np.mean(matrix_total, axis=0))\n",
    "plt.axvline(100, c='r', linestyle='--', linewidth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing gene expression differences systematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, tediously get a dictionary linking names in PATRIC annotations to names in RefSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genome_ref = list(SeqIO.parse('/Users/adamhockenberry/Projects/2017/Genome_database/Data/GBFs/511145.12.RefSeq.gbf', 'genbank'))[0]\n",
    "genome_pat = list(SeqIO.parse('/Users/adamhockenberry/Projects/2017/Genome_database/Data/GBFs/511145.12.PATRIC.gbf', 'genbank'))[0]\n",
    "\n",
    "locs_dict_ref_positive = {}\n",
    "locs_dict_ref_negative = {}\n",
    "\n",
    "locs_dict_pat_positive = {}\n",
    "locs_dict_pat_negative = {}\n",
    "\n",
    "ref_genome_seq_ref_dict = {}\n",
    "ref_genome_seq_patric_dict = {}\n",
    "\n",
    "for feature_pat in genome_pat.features[:]:\n",
    "    if feature_pat.type == 'CDS':\n",
    "        name_pat = feature_pat.qualifiers['locus_tag'][0]\n",
    "        strand_pat = feature_pat.strand\n",
    "        if strand_pat == 1:\n",
    "            locs_dict_pat_positive[name_pat] = list(range(feature_pat.location.start, feature_pat.location.end))\n",
    "            ref_genome_seq_patric_dict[name_pat] = genome_pat.seq[feature_pat.location.start:feature_pat.location.end]\n",
    "        elif strand_pat == -1:\n",
    "            locs_dict_pat_negative[name_pat] = list(range(feature_pat.location.start, feature_pat.location.end))\n",
    "            ref_genome_seq_patric_dict[name_pat] = genome_pat.seq[feature_pat.location.start:feature_pat.location.end].reverse_complement()\n",
    "\n",
    "for feature_ref in genome_ref.features[:]:\n",
    "    if feature_ref.type == 'CDS':\n",
    "        name_ref = feature_ref.qualifiers['locus_tag'][0]\n",
    "        strand_ref = feature_ref.strand\n",
    "        if strand_ref == 1:\n",
    "            locs_dict_ref_positive[name_ref] = list(range(feature_ref.location.start, feature_ref.location.end))\n",
    "            ref_genome_seq_ref_dict[name_ref] = genome_ref.seq[feature_ref.location.start:feature_ref.location.end]\n",
    "\n",
    "        elif strand_ref == -1:\n",
    "            locs_dict_ref_negative[name_ref] = list(range(feature_ref.location.start, feature_ref.location.end))\n",
    "            ref_genome_seq_ref_dict[name_ref] = genome_ref.seq[feature_ref.location.start:feature_ref.location.end].reverse_complement()\n",
    "            \n",
    "print(len(locs_dict_pat_positive.keys()))\n",
    "print(len(locs_dict_pat_negative.keys()))\n",
    "print(len(locs_dict_ref_positive.keys()))\n",
    "print(len(locs_dict_ref_negative.keys()))   \n",
    "\n",
    "reference_name_dict = {}\n",
    "for name_pat, loc_pat in sorted(locs_dict_pat_positive.items()):\n",
    "    for name_ref, loc_ref in sorted(locs_dict_ref_positive.items()):\n",
    "        if len(set(loc_pat)&set(loc_ref)) / len(loc_pat) > 0.9:\n",
    "            reference_name_dict[name_ref] = name_pat\n",
    "            del locs_dict_ref_positive[name_ref]\n",
    "            break\n",
    "            \n",
    "for name_pat, loc_pat in sorted(locs_dict_pat_negative.items()):\n",
    "    for name_ref, loc_ref in sorted(locs_dict_ref_negative.items()):\n",
    "        if len(set(loc_pat)&set(loc_ref)) / len(loc_pat) > 0.9:\n",
    "            reference_name_dict[name_ref] = name_pat\n",
    "            del locs_dict_ref_negative[name_ref]\n",
    "            break\n",
    "print(len(reference_name_dict.keys()), len(ref_genome_seq_patric_dict.keys()), len(ref_genome_seq_ref_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in dataset of protein abundance from PaxDB (integrated dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/adamhockenberry/Downloads/511145/511145-WHOLE_ORGANISM-integrated.txt',\\\n",
    "                 index_col = 'string_external_id', sep='\\t', skiprows=10)\n",
    "expression_dict = {}\n",
    "for index in df.index:\n",
    "    temp_name = index.split('.')[-1]\n",
    "    try:\n",
    "        expression_dict[reference_name_dict[temp_name]] = df.loc[index]['abundance']\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "exp_threshold = np.percentile(list(expression_dict.values()), 50) #TUNABLE PARAMETER\n",
    "expression_subset = []\n",
    "for i,j in expression_dict.items():\n",
    "    if j > exp_threshold:\n",
    "        expression_subset.append(i)\n",
    "print('Number of genes in the expression subset is {}'.format(len(expression_subset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of gene expression values in my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_to_analyze = dicty_hyphy\n",
    "\n",
    "full_listy = []\n",
    "for key in expression_dict.keys():\n",
    "    if key in dict_to_analyze.keys():\n",
    "        full_listy.append(expression_dict[key])\n",
    "print(len(full_listy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentile_20 = np.percentile(full_listy, 20)\n",
    "percentile_40 = np.percentile(full_listy, 40)\n",
    "percentile_60 = np.percentile(full_listy, 60)\n",
    "percentile_80 = np.percentile(full_listy, 80)\n",
    "\n",
    "expression_quantile_dict = {}\n",
    "expression_quantile_dict['lowest'] = []\n",
    "expression_quantile_dict['low'] = []\n",
    "expression_quantile_dict['mid'] = []\n",
    "expression_quantile_dict['high'] = []\n",
    "expression_quantile_dict['highest'] = []\n",
    "\n",
    "for seq_name in dict_to_analyze:\n",
    "    if seq_name not in expression_dict.keys():\n",
    "        continue\n",
    "    if expression_dict[seq_name] < percentile_20:\n",
    "        expression_quantile_dict['lowest'].append(seq_name)\n",
    "    elif expression_dict[seq_name] >= percentile_20 and expression_dict[seq_name] < percentile_40:\n",
    "        expression_quantile_dict['low'].append(seq_name)\n",
    "    elif expression_dict[seq_name] >= percentile_40 and expression_dict[seq_name] < percentile_60:\n",
    "        expression_quantile_dict['mid'].append(seq_name)\n",
    "    elif expression_dict[seq_name] >= percentile_60 and expression_dict[seq_name] < percentile_80:\n",
    "        expression_quantile_dict['high'].append(seq_name)\n",
    "    elif expression_dict[seq_name] >= percentile_80 :\n",
    "        expression_quantile_dict['highest'].append(seq_name)\n",
    "    \n",
    "for key, vals in expression_quantile_dict.items():\n",
    "    print(key, len(vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####Parameters!\n",
    "threshold=-4.5\n",
    "only_conserved_aa=True\n",
    "three_prime_analysis=False\n",
    "controls=['CODON', 'TRINT']\n",
    "\n",
    "meta_codon = []\n",
    "meta_trint = []\n",
    "for cat in ['lowest', 'low', 'mid', 'high', 'highest']:\n",
    "    print('#####{}'.format(cat))\n",
    "    subset_names = expression_quantile_dict[cat]\n",
    "    actual_ratios_codon = []\n",
    "    actual_ratios_trint = []\n",
    "    for i in range(20):\n",
    "        sds, others = paired_nt_analysis(dicty_to_analyze,\\\n",
    "                                     seq_dicty[base_genome],\\\n",
    "                                     fragment_energy_dict,\\\n",
    "                                     asd_seq,\\\n",
    "                                     conservation_dicty,\\\n",
    "                                     threshold=threshold,\\\n",
    "                                     randomization=False,\\\n",
    "                                     subset_names=subset_names,\\\n",
    "                                     only_conserved_aa=only_conserved_aa,\\\n",
    "                                     three_prime_analysis=three_prime_analysis,\\\n",
    "                                     internal_control=controls[0])\n",
    "        actual_ratios_codon.append(np.mean(sds)/np.mean(others))\n",
    "\n",
    "        sds, others = paired_nt_analysis(dicty_to_analyze,\\\n",
    "                             seq_dicty[base_genome],\\\n",
    "                             fragment_energy_dict,\\\n",
    "                             asd_seq,\\\n",
    "                             conservation_dicty,\\\n",
    "                             threshold=threshold,\\\n",
    "                             randomization=False,\\\n",
    "                             subset_names=subset_names,\\\n",
    "                             only_conserved_aa=only_conserved_aa,\\\n",
    "                             three_prime_analysis=three_prime_analysis,\\\n",
    "                             internal_control=controls[1])\n",
    "        actual_ratios_trint.append(np.mean(sds)/np.mean(others))\n",
    "        \n",
    "    meta_codon.append(actual_ratios_codon)\n",
    "    meta_trint.append(actual_ratios_trint)\n",
    "    print(len(sds), np.mean(actual_ratios_codon), np.mean(actual_ratios_trint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(meta_codon[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.violinplot(meta_codon, showextrema=False)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.violinplot(meta_trint, showextrema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codon specific fixed-effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Looking for the consensus nucleotide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_sd = []\n",
    "consensus_other = []\n",
    "sds = []\n",
    "others = []\n",
    "for gene_name, seq in list(seq_dicty[base_genome].items())[:]:\n",
    "    if gene_name not in dicty_hyphy.keys():\n",
    "        continue\n",
    "    codon_list = [seq[nt:nt+3] for nt in range(0, len(seq), 3)]\n",
    "    energy_list = []\n",
    "    for i in range(0, len(seq)-len(asd_seq)):\n",
    "        fragment = seq[i:i+len(asd_seq)]\n",
    "        if fragment.count('-') == 0:\n",
    "            energy = fragment_energy_dict[fragment.replace('T', 'U')]\n",
    "            energy_list.append(energy)\n",
    "        else:\n",
    "            energy_list.append(np.nan)\n",
    "    analyzed_positions = []\n",
    "    sd_positions = [list(range(i, i+6)) for i,j in enumerate(energy_list) if j < threshold]\n",
    "#     sd_positions = [list(range(i, i+6)) for i,j in enumerate(energy_list) if thresholdA < j < thresholdB]\n",
    "    sd_positions = [item for sublist in sd_positions for item in sublist]\n",
    "    sd_positions = list(set(sd_positions))\n",
    "    for i, energy in enumerate(energy_list):\n",
    "        modifiers = []\n",
    "        if energy < threshold and i > 100 and i < len(seq)-50:\n",
    "#         if thresholdA < energy < thresholdB and i > 100 and i < len(seq)-50:\n",
    "#         if energy < threshold and i > 100 and i < len(seq)-50 and gene_name in expression_subset:\n",
    "#         if energy < threshold and i > 50 and i < len(seq)-50 and gene_name in long_genes:\n",
    "#         if energy < threshold and i > len(seq)-50 and gene_name in preceding_genes:\n",
    "#         if energy < threshold and i > len(seq)-50 and gene_name not in preceding_genes:\n",
    "            if i%3 == 0:\n",
    "                modifiers = [2]\n",
    "            elif i%3 == 2:\n",
    "                modifiers = [3]\n",
    "            elif i%3 == 1:\n",
    "                modifiers = [1,4]\n",
    "            for modifier in modifiers:\n",
    "                if conservation_dicty[gene_name][int(np.floor((i+modifier)/3.))] != 'C':\n",
    "                    continue\n",
    "                codon = seq[i+modifier-2:i+modifier+1]\n",
    "                if codon in redundant_codons:\n",
    "                    fragment = seq[i:i+len(asd_seq)]\n",
    "                    assert fragment_energy_dict[fragment.replace('T', 'U')] == energy\n",
    "                    all_codons = aa_to_codon_dict[codon_to_aa_dict[codon]]\n",
    "                    possible_energies = []\n",
    "                    for possible_codon in all_codons:\n",
    "                        if possible_codon != codon:\n",
    "                            if modifier == 2:\n",
    "                                possible_fragment = possible_codon + fragment[-3:]\n",
    "                            elif modifier == 3:\n",
    "                                possible_fragment = fragment[0] + possible_codon + fragment[-2:]\n",
    "                            elif modifier == 1:\n",
    "                                possible_fragment = possible_codon[-2:] + fragment[-4:]\n",
    "                            elif modifier == 4:\n",
    "                                possible_fragment = fragment[0:2] + possible_codon + fragment[-1]\n",
    "                            assert len(possible_fragment) == 6\n",
    "                            possible_energies.append(fragment_energy_dict[possible_fragment.replace('T', 'U')])\n",
    "\n",
    "#                     if len(possible_energies) == 0:\n",
    "#                         continue\n",
    "#                     if energy > min(possible_energies):\n",
    "#                         continue\n",
    "                    if energy < max(possible_energies):\n",
    "                        continue\n",
    "#                     if energy > max(possible_energies) or energy < min(possible_energies):\n",
    "#                         continue\n",
    "                    control_sites = [j*3+2 for j, x in enumerate(codon_list) if x == codon]\n",
    "                    control_sites = [j for j in control_sites if j not in sd_positions and j > 100 and j < len(seq)-50]\n",
    "                    control_sites = [j for j in control_sites if conservation_dicty[gene_name][int(np.floor(j/3.))] == 'C']\n",
    "                    control_sites = [j for j in control_sites if j not in analyzed_positions]\n",
    "                    if len(control_sites) > 0 and i+modifier not in analyzed_positions:\n",
    "                        choice = random.choice(control_sites)\n",
    "#                         sds.append(dicty_phylop[gene_name][i+modifier])\n",
    "#                         others.append(dicty_phylop[gene_name][choice])\n",
    "                        sds.append(dicty_hyphy[gene_name][i+modifier])\n",
    "                        others.append(dicty_hyphy[gene_name][choice])\n",
    "                        analyzed_positions.append(i+modifier)\n",
    "                        analyzed_positions.append(choice)\n",
    "                        if nt_consensus_dicty[gene_name][i+modifier] == seq_dicty[base_genome][gene_name][i+modifier]:\n",
    "                            consensus_sd.append(1)\n",
    "                        else:\n",
    "                            consensus_sd.append(0)\n",
    "                            \n",
    "                        if nt_consensus_dicty[gene_name][choice] == seq_dicty[base_genome][gene_name][choice]:\n",
    "                            consensus_other.append(1)\n",
    "                        else:\n",
    "                            consensus_other.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sds), len(others), len(consensus_sd), len(consensus_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(consensus_sd), sum(consensus_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "84/93, 74/93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "222/326, 257/326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "307/394, 283/394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1172/1845, 1360/1845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "violin_parts = ax.violinplot([np.array(sds)-np.array(others), np.array(sds)-np.array(others)],\\\n",
    "                             vert=False, showextrema=False, showmeans=True, widths=0.75)\n",
    "for pc in violin_parts['bodies']:\n",
    "    pc.set_facecolor('gray')\n",
    "    pc.set_edgecolor('gray')\n",
    "    pc.set_alpha(0.55)\n",
    "violin_parts['cmeans'].set_edgecolor('r')\n",
    "ax.set_xlim(-1,1)\n",
    "\n",
    "\n",
    "# ax.set_xlabel('Difference (SD - Control)');\n",
    "# ax.set_ylabel('counts');\n",
    "# ax.axvline(np.mean(np.array(sds)-np.array(others)), c='c', linewidth=2)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violin_parts['bodies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_rats = []\n",
    "shuffled_rats = []\n",
    "for i in range(100):\n",
    "    sds, others = paired_analysis_trint_control(dicty_hyphy, seq_dicty[base_genome],\\\n",
    "                                            fragment_energy_dict, asd_seq, conservation_dicty,\\\n",
    "                                                subset_names = False,\\\n",
    "                                               randomization=False,\\\n",
    "                                               only_conserved_aa=False)\n",
    "    actual_rats.append(np.mean(sds)/np.mean(others))\n",
    "    print(i, len(sds))\n",
    "    \n",
    "#     sds, others = paired_analysis_codon_control(dicty_hyphy, seq_dicty[base_genome],\\\n",
    "#                                             fragment_energy_dict, asd_seq, conservation_dicty,\\\n",
    "#                                                randomization=True)\n",
    "#     shuffled_rats.append(np.mean(sds)/np.mean(others))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(actual_rats, alpha=0.5)\n",
    "# plt.hist(shuffled_rats, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(stats.ttest_ind(actual_rats, shuffled_rats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "228px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
