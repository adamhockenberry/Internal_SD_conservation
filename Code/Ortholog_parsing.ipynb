{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import Counter\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from Bio.Data import IUPACData \n",
    "import os.path; os.rename\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get relevant genomes and write FAA and FNA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genbank_to_faa_and_fna(genbank_filename, ignore_plasmid=True):\n",
    "    genome_name = genbank_filename.split('/')[-1].rstrip('.PATRIC.gbf')\n",
    "    faa_filename = genbank_filename.replace('gbf', 'faa').replace('GBFs', 'FAAs')\n",
    "    fna_filename = genbank_filename.replace('gbf', 'fna').replace('GBFs', 'FNAs')\n",
    "    \n",
    "    output_handle_faa = open(faa_filename, \"w\")\n",
    "    output_handle_fna = open(fna_filename, \"w\")\n",
    "\n",
    "\n",
    "    for seq_record in SeqIO.parse(genbank_filename, \"genbank\"):\n",
    "        if ignore_plasmid:\n",
    "            if seq_record.description.lower().find('plasmid') != -1:\n",
    "                continue\n",
    "        for seq_feature in seq_record.features[:]: #Use slicing to truncate search for testing purposes\n",
    "            if seq_feature.type==\"CDS\":\n",
    "                strand = seq_feature.strand\n",
    "                beg = seq_feature.location.start\n",
    "                end = seq_feature.location.end\n",
    "                if strand == 1:\n",
    "                    nt_seq = seq_record.seq[beg:end]\n",
    "                elif strand == -1:\n",
    "                    nt_seq = seq_record.seq[beg:end].reverse_complement()\n",
    "                else:\n",
    "                    print('catastrophic error')\n",
    "                if len(nt_seq) > 90 and len(nt_seq) % 3 == 0:\n",
    "                    aa_seq = nt_seq.translate()\n",
    "                    aa_seq = aa_seq[:-1]\n",
    "                    nt_seq = nt_seq[:-3]\n",
    "                    if len(set(str(aa_seq)+IUPACData.protein_letters))!= 20:\n",
    "                        continue\n",
    "                    if len(set(str(nt_seq)+IUPACData.unambiguous_dna_letters))!= 4:\n",
    "                        continue\n",
    "                    output_handle_faa.write(\">{}|{}\\n{}\\n\".format(\n",
    "                            seq_feature.qualifiers['locus_tag'][0], \n",
    "                            genome_name, \n",
    "                            str(aa_seq)))\n",
    "                    output_handle_fna.write(\">{}|{}\\n{}\\n\".format(\n",
    "                            seq_feature.qualifiers['locus_tag'][0], \n",
    "                            genome_name, \n",
    "                            str(nt_seq)))\n",
    "\n",
    "    output_handle_faa.close()\n",
    "    output_handle_fna.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "genome_grouping = 'representative'\n",
    "df_rep = pd.read_csv('../../Genome_database/Data/Dataframes/PATRIC_genome_complete_bacteria_{}_taxon.csv'.format(genome_grouping), index_col = 'Genome ID')\n",
    "df_rep = df_rep[(df_rep['order']=='Enterobacterales')  & (df_rep['PATRIC CDS'] > 2000)]\n",
    "print(len(df_rep.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "genome_grouping = 'reference'\n",
    "df_ref = pd.read_csv('../../Genome_database/Data/Dataframes/PATRIC_genome_complete_bacteria_{}_taxon.csv'.format(genome_grouping), index_col = 'Genome ID')\n",
    "df_ref = df_ref[(df_ref['order']=='Enterobacterales')  & (df_ref['PATRIC CDS'] > 2000)]\n",
    "print(len(df_ref.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 102\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_rep, df_ref])\n",
    "print(len(df.index), len(list(set(list(df.index)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "species_list = list(set(list(df[df['species'].isnull()==False]['species'])))\n",
    "print(len(species_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_to_drop = []\n",
    "for index in df.index:\n",
    "    genbank_filename = '../../Genome_database/Data/GBFs/{}.PATRIC.gbf'.format(index)\n",
    "    if os.path.isfile(genbank_filename) == False:\n",
    "        rows_to_drop.append(index)\n",
    "df = df.drop(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows_to_drop = []\n",
    "\n",
    "for index in df.index:\n",
    "    if index in [511145.12, 99287.12]:\n",
    "        pass\n",
    "    elif df.loc[index]['species'] in ['Escherichia coli', 'Salmonella enterica']:\n",
    "        rows_to_drop.append(index)\n",
    "\n",
    "for species in species_list:\n",
    "    if species in ['Escherichia coli', 'Salmonella enterica']:\n",
    "        continue\n",
    "    reference = False\n",
    "    hits = []\n",
    "    for index in df[df['species'].isnull()==False].index:\n",
    "        if df.loc[index]['species'] == species:\n",
    "            hits.append(index)\n",
    "    for hit in hits:\n",
    "        if hit in df_ref.index:\n",
    "            reference = True\n",
    "    if reference == True:\n",
    "        for hit in hits:\n",
    "            if hit not in df_ref.index:\n",
    "                rows_to_drop.append(hit)\n",
    "    else:\n",
    "        for hit in hits[1:]:\n",
    "            rows_to_drop.append(hit)\n",
    "df = df.drop(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in df.index[:]: #Use slicing to truncate data for testing\n",
    "    genbank_filename = '../../Genome_database/Data/GBFs/{}.PATRIC.gbf'.format(index)\n",
    "    print(index)\n",
    "    if os.path.isfile(genbank_filename): \n",
    "        genbank_to_faa_and_fna(genbank_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline: Run reciprocal blast on the amino acid files to find orthologs\n",
    "\n",
    "This code is currently in Code/BASH in reciprocal_blast_all.sh\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push some files around and do some clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for infile in glob.glob('../Data/FAAs/*.faa'):\n",
    "    os.rename(infile, infile.replace('/FAAs/', '/FAAs/Order_Enterobacterales_Representative/'))\n",
    "for infile in glob.glob('../Data/FNAs/*.fna'):\n",
    "    os.rename(infile, infile.replace('/FNAs/', '/FNAs/Order_Enterobacterales_Representative/'))\n",
    "for infile in glob.glob('../Data/Orthologs/*.u8'):\n",
    "    os.rename(infile, infile.replace('/Orthologs/', '/Orthologs/Order_Enterobacterales_Representative/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(glob.glob('../Data/FAAs/Order_Enterobacterales_Representative/*.faa')))\n",
    "print(len(glob.glob('../Data/FNAs/Order_Enterobacterales_Representative/*.fna')))\n",
    "print(len(glob.glob('../Data/Orthologs/Order_Enterobacterales_Representative/*.u8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse through all ortholog files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "base_genome = '511145.12'\n",
    "# directory_to_read = '../Data/Orthologs/Order_Enterobacterales_Representative/'\n",
    "# print(len(glob.glob('../Data/Orthologs/Order_Enterobacterales_Representative/*.u8')))\n",
    "directory_to_read = '../Data/Orthologs/Order_Enterobacterales_Mixed/'\n",
    "print(len(glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/*.u8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "511145.12 1006551.4\n",
      "##########\n",
      "511145.12 1028307.3\n",
      "##########\n",
      "511145.12 1076550.3\n",
      "##########\n",
      "511145.12 1125630.4\n",
      "##########\n",
      "511145.12 1157951.4\n",
      "##########\n",
      "511145.12 1166016.3\n",
      "##########\n",
      "511145.12 1235834.6\n",
      "##########\n",
      "511145.12 1239307.3\n",
      "##########\n",
      "511145.12 1249634.3\n",
      "##########\n",
      "511145.12 1286170.3\n",
      "##########\n",
      "511145.12 1333848.3\n",
      "##########\n",
      "511145.12 1441930.4\n",
      "##########\n",
      "511145.12 1484157.3\n",
      "##########\n",
      "511145.12 158822.6\n",
      "##########\n",
      "511145.12 158822.7\n",
      "##########\n",
      "511145.12 198214.7\n",
      "##########\n",
      "511145.12 198628.6\n",
      "##########\n",
      "511145.12 214092.21\n",
      "##########\n",
      "511145.12 215689.3\n",
      "##########\n",
      "511145.12 218491.5\n",
      "##########\n",
      "511145.12 218493.5\n",
      "##########\n",
      "511145.12 243265.5\n",
      "##########\n",
      "511145.12 290338.8\n",
      "##########\n",
      "511145.12 290339.8\n",
      "##########\n",
      "511145.12 291112.3\n",
      "##########\n",
      "511145.12 300267.13\n",
      "##########\n",
      "511145.12 300268.11\n",
      "##########\n",
      "511145.12 300269.12\n",
      "##########\n",
      "511145.12 343509.12\n",
      "##########\n",
      "511145.12 393305.7\n",
      "##########\n",
      "511145.12 399741.7\n",
      "##########\n",
      "511145.12 406818.4\n",
      "##########\n",
      "511145.12 465817.9\n",
      "##########\n",
      "511145.12 498217.4\n",
      "##########\n",
      "511145.12 502801.6\n",
      "##########\n",
      "511145.12 1006551.4\n",
      "##########\n",
      "511145.12 1028307.3\n",
      "##########\n",
      "511145.12 1076550.3\n",
      "##########\n",
      "511145.12 1125630.4\n",
      "##########\n",
      "511145.12 1157951.4\n",
      "##########\n",
      "511145.12 1166016.3\n",
      "##########\n",
      "511145.12 1235834.6\n",
      "##########\n",
      "511145.12 1239307.3\n",
      "##########\n",
      "511145.12 1249634.3\n",
      "##########\n",
      "511145.12 1286170.3\n",
      "##########\n",
      "511145.12 1333848.3\n",
      "##########\n",
      "511145.12 1441930.4\n",
      "##########\n",
      "511145.12 1484157.3\n",
      "##########\n",
      "511145.12 158822.6\n",
      "##########\n",
      "511145.12 158822.7\n",
      "##########\n",
      "511145.12 198214.7\n",
      "##########\n",
      "511145.12 198628.6\n",
      "##########\n",
      "511145.12 214092.21\n",
      "##########\n",
      "511145.12 215689.3\n",
      "##########\n",
      "511145.12 218491.5\n",
      "##########\n",
      "511145.12 218493.5\n",
      "##########\n",
      "511145.12 243265.5\n",
      "##########\n",
      "511145.12 290338.8\n",
      "##########\n",
      "511145.12 290339.8\n",
      "##########\n",
      "511145.12 291112.3\n",
      "##########\n",
      "511145.12 300267.13\n",
      "##########\n",
      "511145.12 300268.11\n",
      "##########\n",
      "511145.12 300269.12\n",
      "##########\n",
      "511145.12 343509.12\n",
      "##########\n",
      "511145.12 393305.7\n",
      "##########\n",
      "511145.12 399741.7\n",
      "##########\n",
      "511145.12 406818.4\n",
      "##########\n",
      "511145.12 465817.9\n",
      "##########\n",
      "511145.12 498217.4\n",
      "##########\n",
      "511145.12 502801.6\n",
      "##########\n",
      "511145.12 529507.6\n",
      "##########\n",
      "511145.12 553.3\n",
      "##########\n",
      "511145.12 561229.3\n",
      "##########\n",
      "511145.12 561230.3\n",
      "##########\n",
      "511145.12 561231.5\n",
      "##########\n",
      "511145.12 579405.3\n",
      "##########\n",
      "511145.12 585054.5\n",
      "##########\n",
      "511145.12 592316.4\n",
      "##########\n",
      "511145.12 630626.3\n",
      "##########\n",
      "511145.12 634499.3\n",
      "##########\n",
      "511145.12 634500.5\n",
      "##########\n",
      "511145.12 634503.3\n",
      "##########\n",
      "511145.12 637910.3\n",
      "##########\n",
      "511145.12 640131.3\n",
      "##########\n",
      "511145.12 640513.3\n",
      "##########\n",
      "511145.12 665029.3\n",
      "##########\n",
      "511145.12 693216.3\n",
      "##########\n",
      "511145.12 693444.3\n",
      "##########\n",
      "511145.12 701347.4\n",
      "##########\n",
      "511145.12 716541.4\n",
      "##########\n",
      "511145.12 741091.4\n",
      "##########\n",
      "511145.12 745277.3\n",
      "##########\n",
      "511145.12 768490.3\n",
      "##########\n",
      "511145.12 768492.3\n",
      "##########\n",
      "511145.12 99287.12\n",
      "##########\n",
      "511145.12 529507.6\n",
      "##########\n",
      "511145.12 553.3\n",
      "##########\n",
      "511145.12 561229.3\n",
      "##########\n",
      "511145.12 561230.3\n",
      "##########\n",
      "511145.12 561231.5\n",
      "##########\n",
      "511145.12 579405.3\n",
      "##########\n",
      "511145.12 585054.5\n",
      "##########\n",
      "511145.12 592316.4\n",
      "##########\n",
      "511145.12 630626.3\n",
      "##########\n",
      "511145.12 634499.3\n",
      "##########\n",
      "511145.12 634500.5\n",
      "##########\n",
      "511145.12 634503.3\n",
      "##########\n",
      "511145.12 637910.3\n",
      "##########\n",
      "511145.12 640131.3\n",
      "##########\n",
      "511145.12 640513.3\n",
      "##########\n",
      "511145.12 665029.3\n",
      "##########\n",
      "511145.12 693216.3\n",
      "##########\n",
      "511145.12 693444.3\n",
      "##########\n",
      "511145.12 701347.4\n",
      "##########\n",
      "511145.12 716541.4\n",
      "##########\n",
      "511145.12 741091.4\n",
      "##########\n",
      "511145.12 745277.3\n",
      "##########\n",
      "511145.12 768490.3\n",
      "##########\n",
      "511145.12 768492.3\n",
      "##########\n",
      "511145.12 99287.12\n"
     ]
    }
   ],
   "source": [
    "ecoli_dict = {}\n",
    "comparison_genome_names = []\n",
    "for infile in glob.glob('{}*{}*.u8'.format(directory_to_read, base_genome))[:]:\n",
    "    comparison_genome = infile.split('/')[-1].replace(base_genome, '').replace('_vs_', '').replace('.u8', '')\n",
    "    print('##########')\n",
    "    print(base_genome, comparison_genome)\n",
    "    comparison_genome_names.append(comparison_genome)\n",
    "    if infile.find(base_genome) < infile.find('_vs_'):\n",
    "        base_entry = 0\n",
    "        comparison_entry = 1\n",
    "    elif infile.find(base_genome) > infile.find('_vs_'):\n",
    "        base_entry = 1\n",
    "        comparison_entry = 0\n",
    "    else:\n",
    "        print('Error, investigate')\n",
    "        break\n",
    "    \n",
    "    temp_dict = {}\n",
    "    with open(infile) as blastdata:\n",
    "        for line in blastdata:\n",
    "            split_line = line.split('\\t')\n",
    "            try:\n",
    "                temp_dict[split_line[base_entry]].append((split_line[comparison_entry], float(split_line[2])))    \n",
    "            except KeyError:\n",
    "                temp_dict[split_line[base_entry]] = [(split_line[comparison_entry], float(split_line[2]))]\n",
    "\n",
    "    for i,j in temp_dict.items():\n",
    "        if len(j) == 1:\n",
    "            try:\n",
    "                ecoli_dict[i].append(j[0][0])\n",
    "            except KeyError:\n",
    "                ecoli_dict[i] = [j[0][0]]\n",
    "        elif len(j) > 1:\n",
    "            try:\n",
    "                ecoli_dict[i].append(sorted(j, key=lambda x: x[1])[-1][0])\n",
    "            except KeyError:\n",
    "                ecoli_dict[i] = [sorted(j, key=lambda x: x[1])[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 60\n"
     ]
    }
   ],
   "source": [
    "print(len(comparison_genome_names), len(set(comparison_genome_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'300269.12': 7661, '198214.7': 7527, '300268.11': 7297, '300267.13': 6917, '585054.5': 6638, '1333848.3': 6277, '290338.8': 6030, '637910.3': 5986, '99287.12': 5896, '218493.5': 5770, '716541.4': 5548, '693444.3': 5541, '701347.4': 5527, '640513.3': 5412, '1006551.4': 5374, '1125630.4': 5300, '1028307.3': 5287, '640131.3': 5251, '1286170.3': 5248, '1235834.6': 5102, '158822.6': 4694, '158822.7': 4627, '290339.8': 4612, '693216.3': 4593, '630626.3': 4148, '399741.7': 3523, '1484157.3': 3515, '768490.3': 3407, '768492.3': 3405, '634500.5': 3364, '1249634.3': 3339, '1441930.4': 3255, '592316.4': 3252, '393305.7': 3219, '1076550.3': 3219, '745277.3': 3193, '741091.4': 3191, '553.3': 3174, '561230.3': 3107, '218491.5': 3093, '1166016.3': 3080, '561231.5': 3076, '502801.6': 3052, '214092.21': 3046, '198628.6': 2910, '561229.3': 2892, '465817.9': 2892, '215689.3': 2863, '665029.3': 2841, '634499.3': 2835, '579405.3': 2811, '1239307.3': 2703, '498217.4': 2694, '634503.3': 2605, '343509.12': 2465, '243265.5': 2233, '291112.3': 2224, '1157951.4': 2192, '406818.4': 2127, '529507.6': 2095})\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "listy = []\n",
    "for i,j in list(ecoli_dict.items())[:]:\n",
    "    listy.extend([record.split('|')[-1] for record in j])\n",
    "print(Counter(listy))\n",
    "print(len(Counter(listy).keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use above information to delete genomes with an outlying few number of orthologs before proceeding\n",
    "\n",
    "You MUST go back up and re-run the ecoli_dict code in order to proceed after you delete any genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_apples = ['572265.5']\n",
    "for bad_apple in bad_apples:\n",
    "    os.remove('../Data/FNAs/{}.PATRIC.fna'.format(bad_apple))\n",
    "    os.remove('../Data/FAAs/{}.PATRIC.faa'.format(bad_apple))\n",
    "    for trash_file in glob.glob('../Data/Orthologs/*{}*.u8'.format(bad_apple)):\n",
    "        os.remove(trash_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out how many orthologs we'll have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394\n"
     ]
    }
   ],
   "source": [
    "looking_good = 0\n",
    "for i,j in list(ecoli_dict.items())[:]:\n",
    "    temp_counter = Counter(j)\n",
    "    if len(set(temp_counter.values())) == 1:\n",
    "        if list(set(temp_counter.values()))[0] == 2:\n",
    "            if len(temp_counter.keys()) >= int(0.70 * len(set(comparison_genome_names))): #Tunable paramater HERE\n",
    "                    looking_good += 1\n",
    "#                     print(temp_counter)\n",
    "print(looking_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all amino acid squences into a giant dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/FAAs/1006551.4.PATRIC.faa\n",
      "../Data/FAAs/1028307.3.PATRIC.faa\n",
      "../Data/FAAs/1076550.3.PATRIC.faa\n",
      "../Data/FAAs/1125630.4.PATRIC.faa\n",
      "../Data/FAAs/1157951.4.PATRIC.faa\n",
      "../Data/FAAs/1166016.3.PATRIC.faa\n",
      "../Data/FAAs/1235834.6.PATRIC.faa\n",
      "../Data/FAAs/1239307.3.PATRIC.faa\n",
      "../Data/FAAs/1249634.3.PATRIC.faa\n",
      "../Data/FAAs/1286170.3.PATRIC.faa\n",
      "../Data/FAAs/1333848.3.PATRIC.faa\n",
      "../Data/FAAs/1441930.4.PATRIC.faa\n",
      "../Data/FAAs/1484157.3.PATRIC.faa\n",
      "../Data/FAAs/158822.6.PATRIC.faa\n",
      "../Data/FAAs/158822.7.PATRIC.faa\n",
      "../Data/FAAs/198214.7.PATRIC.faa\n",
      "../Data/FAAs/198628.6.PATRIC.faa\n",
      "../Data/FAAs/214092.21.PATRIC.faa\n",
      "../Data/FAAs/215689.3.PATRIC.faa\n",
      "../Data/FAAs/218491.5.PATRIC.faa\n",
      "../Data/FAAs/218493.5.PATRIC.faa\n",
      "../Data/FAAs/243265.5.PATRIC.faa\n",
      "../Data/FAAs/290338.8.PATRIC.faa\n",
      "../Data/FAAs/290339.8.PATRIC.faa\n",
      "../Data/FAAs/291112.3.PATRIC.faa\n",
      "../Data/FAAs/300267.13.PATRIC.faa\n",
      "../Data/FAAs/300268.11.PATRIC.faa\n",
      "../Data/FAAs/300269.12.PATRIC.faa\n",
      "../Data/FAAs/343509.12.PATRIC.faa\n",
      "../Data/FAAs/393305.7.PATRIC.faa\n",
      "../Data/FAAs/399741.7.PATRIC.faa\n",
      "../Data/FAAs/406818.4.PATRIC.faa\n",
      "../Data/FAAs/465817.9.PATRIC.faa\n",
      "../Data/FAAs/498217.4.PATRIC.faa\n",
      "../Data/FAAs/502801.6.PATRIC.faa\n",
      "../Data/FAAs/511145.12.PATRIC.faa\n",
      "../Data/FAAs/529507.6.PATRIC.faa\n",
      "../Data/FAAs/553.3.PATRIC.faa\n",
      "../Data/FAAs/561229.3.PATRIC.faa\n",
      "../Data/FAAs/561230.3.PATRIC.faa\n",
      "../Data/FAAs/561231.5.PATRIC.faa\n",
      "../Data/FAAs/579405.3.PATRIC.faa\n",
      "../Data/FAAs/585054.5.PATRIC.faa\n",
      "../Data/FAAs/592316.4.PATRIC.faa\n",
      "../Data/FAAs/630626.3.PATRIC.faa\n",
      "../Data/FAAs/634499.3.PATRIC.faa\n",
      "../Data/FAAs/634500.5.PATRIC.faa\n",
      "../Data/FAAs/634503.3.PATRIC.faa\n",
      "../Data/FAAs/637910.3.PATRIC.faa\n",
      "../Data/FAAs/640131.3.PATRIC.faa\n",
      "../Data/FAAs/640513.3.PATRIC.faa\n",
      "../Data/FAAs/665029.3.PATRIC.faa\n",
      "../Data/FAAs/693216.3.PATRIC.faa\n",
      "../Data/FAAs/693444.3.PATRIC.faa\n",
      "../Data/FAAs/701347.4.PATRIC.faa\n",
      "../Data/FAAs/716541.4.PATRIC.faa\n",
      "../Data/FAAs/741091.4.PATRIC.faa\n",
      "../Data/FAAs/745277.3.PATRIC.faa\n",
      "../Data/FAAs/768490.3.PATRIC.faa\n",
      "../Data/FAAs/768492.3.PATRIC.faa\n",
      "../Data/FAAs/99287.12.PATRIC.faa\n"
     ]
    }
   ],
   "source": [
    "aa_sequence_dict = {}\n",
    "for i in glob.glob('../Data/FAAs/*.faa')[:]:\n",
    "    print(i)\n",
    "    records = SeqIO.parse(i, 'fasta')\n",
    "    for record in records:\n",
    "        aa_sequence_dict[record.description] = str(record.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And create new .fasta files that can be used by MUSCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,j in list(ecoli_dict.items())[:]:\n",
    "    temp_counter = Counter(j)\n",
    "    if len(set(temp_counter.values())) == 1:\n",
    "        if list(set(temp_counter.values()))[0] == 2:\n",
    "            if len(temp_counter.keys()) >= int(0.70 * len(set(comparison_genome_names))):\n",
    "                with open('../Data/Orthologs/Order_Enterobacterales_Mixed/fastas/{}.fasta'.format(i.split('|')[0].strip()), 'w') as outfile:\n",
    "                    outfile.write('>{}\\n{}\\n'.format(i, aa_sequence_dict[i]))\n",
    "                    for ortho in temp_counter.keys():\n",
    "                        outfile.write('>{}\\n{}\\n'.format(ortho, aa_sequence_dict[ortho]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline: Run MUSCLE on the amino acid ortholog files to get .mfastas\n",
    "\n",
    "Look into MAFFT\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and parse (some of) the .mfastas to write concatenated, aligned aa seqs for use in making an amino acid tree for overall topology purposes\n",
    "\n",
    "This is kind of limited by the power of my computer right now. Would love to submit them all to RAxML but it'll take too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = glob.glob('../Data/FAAs/*.faa')\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_indels = []\n",
    "for i in glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/mfastas/*.mfasta')[:]:\n",
    "#     print(i)\n",
    "    records = list(SeqIO.parse(i, 'fasta'))\n",
    "    total_indel_locs = []\n",
    "    for record in records:\n",
    "        total_indel_locs.append(str(record.seq).count('-'))\n",
    "    if sum(total_indel_locs) <= 0.01*len(records)*len(records[0].seq) and len(records) == len(all_files):\n",
    "        no_indels.append(i)\n",
    "print(len(no_indels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_sequence_dict = {}\n",
    "# for i in glob.glob('../Data/Orthologs/Order_Enterobacterales_Representative/mfastas/*.mfasta')[:]:\n",
    "for i in no_indels[:]:\n",
    "    print(i)\n",
    "    records = SeqIO.parse(i, 'fasta')\n",
    "    for record in records:\n",
    "        try:\n",
    "            full_sequence_dict[record.description.split('|')[-1].strip()] += str(record.seq)\n",
    "        except KeyError:\n",
    "            full_sequence_dict[record.description.split('|')[-1].strip()] = str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(full_sequence_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../Data/Tree_files/Order_Enterobacterales_Mixed/full_aligned_aas_108_seqs.mfasta', 'w') as outfile:\n",
    "    for i,j in full_sequence_dict.items():\n",
    "        outfile.write('>{}\\n{}\\n'.format(i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline: Run RAxML on aligned and concatenated aa seqs to make a tree\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run phyloFit to get neutral rates, this will remove branch lengths from tree topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../Data/Tree_files/RAxML_bestTree.FIRST100CDS', 'newick')\n",
    "# Phylo.write(tree, '../Data/Tree_files/RAxML_bestTree.FIRST100CDSFLAT', 'newick', plain=True);\n",
    "# tree = Phylo.read('../Data/Tree_files/Order_Enterobacterales_Reference/RAxML_bestTree.ReferenceSet232seqs', 'newick')\n",
    "# Phylo.write(tree, '../Data/Tree_files/Order_Enterobacterales_Reference/RAxML_bestTree.ReferenceSet232seqsFLAT', 'newick', plain=True);\n",
    "tree = Phylo.read('../Data/Tree_files/Order_Enterobacterales_Mixed/RAxML_bestTree.MixedSet108seqs', 'newick')\n",
    "Phylo.write(tree, '../Data/Tree_files/Order_Enterobacterales_Mixed/RAxML_bestTree.MixedSet108seqsFLAT', 'newick', plain=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up, take aligned .mfasta files in amino acid form and write their equivalents in nucleotide sequence form\n",
    "\n",
    "### I wrote this pretty quickly and it's important so go back and test this to make behavior is as expected\n",
    "### In particular, see how hard it would be to add S, L and R 4-fold redundant codons into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nt_seq_dict = {}\n",
    "for genome_file in glob.glob('../Data/FNAs/*.PATRIC.fna'):\n",
    "    genome_name = genome_file.split('/')[-1].strip('.PATRIC.fna')\n",
    "    nt_seq_dict[genome_name] = {}\n",
    "    for record in SeqIO.parse(genome_file, 'fasta'):\n",
    "        nt_seq_dict[genome_name][record.id] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(list(nt_seq_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redundant_concat_dict = {}\n",
    "for i in nt_seq_dict.keys():\n",
    "    redundant_concat_dict[i] = ''\n",
    "    \n",
    "for infile in glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/mfastas/*.mfasta')[:]:\n",
    "    print(infile)\n",
    "    aln_pro_seq_list = list(SeqIO.parse(infile, format='fasta'))\n",
    "    all_genomes = list(nt_seq_dict.keys())\n",
    "    with open(infile.replace('mfastas', 'mfastas_nt'), 'w') as outfile:\n",
    "        codon_alns = {}\n",
    "        for i in aln_pro_seq_list:\n",
    "            genome_name = i.description.split('|')[-1]\n",
    "            seq_str = str(nt_seq_dict[genome_name][i.id].seq)\n",
    "            codon_list = [seq_str[nt:nt+3] for nt in range(0, len(seq_str), 3)]\n",
    "            aa_str = str(nt_seq_dict[genome_name][i.id].seq.translate())\n",
    "            codon_list_new = []\n",
    "            minus = 0\n",
    "            for pos,aa in enumerate(str(i.seq).rstrip('-')):\n",
    "                if aa_str[pos-minus] == aa:\n",
    "                    codon_list_new.append(codon_list[pos-minus])\n",
    "                else:\n",
    "                    codon_list_new.append('---')\n",
    "                    minus += 1\n",
    "            for terminal in range(len(str(i.seq)) - len(str(i.seq).rstrip('-'))):\n",
    "                codon_list_new.append('---')\n",
    "            new_nt_seq = ''.join(codon_list_new)\n",
    "            outfile.write('>{}\\n{}\\n'.format(genome_name, new_nt_seq))\n",
    "            all_genomes.remove(genome_name)\n",
    "            codon_alns[genome_name] = codon_list_new\n",
    "        \n",
    "        for genome_name in all_genomes:\n",
    "            outfile.write('>{}\\n{}\\n'.format(genome_name, ''.join(['-' for i in range(len(new_nt_seq))])))\n",
    "            codon_alns[genome_name] = ['---' for i in range(len(codon_list_new))]\n",
    "            \n",
    "        if len(aln_pro_seq_list) >= 1 * len(list(nt_seq_dict.keys())): \n",
    "#             print('testing this one')\n",
    "            hits = 0\n",
    "            total_len = len(aln_pro_seq_list[0].seq)\n",
    "            for i in range(total_len):\n",
    "                idents = []\n",
    "                for aa_align in aln_pro_seq_list:\n",
    "                    idents.append(aa_align.seq[i])\n",
    "#                 print(idents)\n",
    "                if len(set(idents)) == 1 and idents[0] in ['P', 'T', 'A', 'V', 'G']:\n",
    "#                 if idents[0] in ['P', 'T', 'A', 'V', 'G']:\n",
    "                    for genome_name, codon_list in codon_alns.items():\n",
    "                        redundant_concat_dict[genome_name] += codon_list[i][-1]\n",
    "#                         print(codon_list[i])\n",
    "                    hits += 1\n",
    "#             print(hits, total_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure they're all the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for infile in glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/mfastas_nt/*.mfasta')[:50]:\n",
    "    print(infile)\n",
    "    aln_nt_seq_list = list(SeqIO.parse(infile, format='fasta'))\n",
    "    lens = []\n",
    "    for i in aln_nt_seq_list:\n",
    "        lens.append(len(i.seq))\n",
    "    print(len(aln_nt_seq_list), set(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, j in redundant_concat_dict.items():\n",
    "    print(len(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/Tree_files/Order_Enterobacterales_Mixed/redundant_nts_align.fasta', 'w') as outfile:\n",
    "    for key, val in redundant_concat_dict.items():\n",
    "        outfile.write('>{}\\n{}\\n'.format(key, val[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test that this alignment worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for infile in glob.glob('../Data/Orthologs/Order_Enterobacterales_Mixed/mfastas/*.mfasta')[:]:\n",
    "#     aln_pro_seq_list = list(SeqIO.parse(infile, format='fasta'))\n",
    "#     aln_nt_seq_list = list(SeqIO.parse(infile.replace('mfastas', 'mfastas_nt'), format='fasta'))\n",
    "#     aln_new_nt_seq_list = [i.seq.split('---') for i in aln_nt_seq_list]\n",
    "#     aln_new_pro_seq_list = [i.seq.split('-') for i in aln_pro_seq_list]\n",
    "#     for i, pro_seqs in enumerate(aln_new_pro_seq_list):\n",
    "#         for j, segment in enumerate(pro_seqs):\n",
    "#             assert segment == aln_new_nt_seq_list[i][j].translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline: Run phyloFit to get a neutral model\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Offline: Run phylogenetic models on nucleotide data (phyloP, HyPhy,etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#         print('#########')\n",
    "#         print(i.seq[:15])\n",
    "#         print(aa_str[:15])\n",
    "#         print(codon_list_new[:15])\n",
    "#         print(codon_list[:15])\n",
    "\n",
    "#         print(i.seq)\n",
    "#         print(nt_seq_dict[genome_name][i.id].seq)\n",
    "#         print(nt_seq_dict[genome_name][i.id].seq.translate())\n",
    "\n",
    "#     aln_nt_seq_list = []\n",
    "#     for i in aln_pro_seq_list:\n",
    "#         nt_seq_of_interest = nt_seq_dict[i.description.split('|')[-1].strip()][i.id]\n",
    "#         nt_seq_of_interest.seq.alphabet = IUPAC.IUPACUnambiguousDNA()\n",
    "#         aln_nt_seq_list.append(nt_seq_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from Bio.Seq import Seq\n",
    ">>> from Bio.Alphabet import IUPAC\n",
    ">>> coding_dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\", IUPAC.unambiguous_dna)\n",
    ">>> coding_dna.translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coding_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nt_seq_dict[genome][i.id].seq.translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing feature.extract and why it's so terrible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biopython_way = []\n",
    "my_way = []\n",
    "genbank_filename = ('../Data/GBFs/511145.12.PATRIC.gbf')\n",
    "ignore_plasmid=True\n",
    "for seq_record in SeqIO.parse(genbank_filename, \"genbank\"):\n",
    "    if ignore_plasmid:\n",
    "        if seq_record.description.lower().find('plasmid') != -1:\n",
    "            continue\n",
    "    for seq_feature in seq_record.features[:]: #Use slicing to truncate search for testing purposes\n",
    "        if seq_feature.type==\"CDS\":\n",
    "            strand = seq_feature.strand\n",
    "#             print('### {}'.format(strand))\n",
    "            nt_seq = seq_feature.extract(seq_record)\n",
    "#             print('Bioython way:', str(nt_seq.seq)[:3], str(nt_seq.seq)[-3:], len(str(nt_seq.seq)))\n",
    "            beg = seq_feature.location.start\n",
    "            end = seq_feature.location.end\n",
    "            if strand == 1:\n",
    "                my_seq = seq_record.seq[beg:end]\n",
    "            elif strand == -1:\n",
    "                my_seq = seq_record.seq[beg:end].reverse_complement()\n",
    "            else:\n",
    "                print('catastrophic error')\n",
    "#             print('My way:', str(my_seq)[:3], str(my_seq)[-3:], len(str(my_seq)))\n",
    "            biopython_way.append(nt_seq.seq)\n",
    "            my_way.append(my_seq)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(biopython_way), len(my_way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biopython_way == my_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_way[0][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genomes_dict = {}\n",
    "for i, a in list(enumerate(df.index))[:]:\n",
    "    if os.path.exists('../Data/GBFs/{}.PATRIC.gbf'.format(a)):\n",
    "        genomes_dict[a] = list(SeqIO.parse('../Data/GBFs/{}.PATRIC.gbf'.format(a), 'genbank'))[0]\n",
    "print('done loading into memory')\n",
    "listy = list(genomes_dict.items())\n",
    "for i, a in enumerate(listy):\n",
    "    print(a[0])\n",
    "    for j, b in list(enumerate(listy))[i+1:]:\n",
    "        if str(a[1].seq) == str(b[1].seq):\n",
    "            print('well fuck me sideways', a[0], b[0])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8178\n",
      "8175\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../../Genome_database/Data/Dataframes/PATRIC_genome_complete_bacteria.csv', index_col='Genome ID')\n",
    "print(len(df_all.index))\n",
    "df_all = df_all[~df_all.index.duplicated(keep='first')]\n",
    "print(len(df_all.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecs = []\n",
    "for index in df_all.index:\n",
    "    if df_all.loc[index]['Genome Name'].find('Escherichia coli') != -1:\n",
    "        ecs.append(df_all.loc[index]['Genome Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "6 6\n"
     ]
    }
   ],
   "source": [
    "genome_grouping = 'representative'\n",
    "df_rep = pd.read_csv('../../Genome_database/Data/Dataframes/PATRIC_genome_complete_bacteria_{}_taxon.csv'.format(genome_grouping), index_col = 'Genome ID')\n",
    "df_rep = df_rep[(df_rep['species']=='Escherichia coli')  & (df_rep['PATRIC CDS'] > 2000)]\n",
    "print(len(df_rep.index))\n",
    "genome_grouping = 'reference'\n",
    "df_ref = pd.read_csv('../../Genome_database/Data/Dataframes/PATRIC_genome_complete_bacteria_{}_taxon.csv'.format(genome_grouping), index_col = 'Genome ID')\n",
    "df_ref = df_ref[(df_ref['species']=='Escherichia coli')  & (df_ref['PATRIC CDS'] > 2000)]\n",
    "print(len(df_ref.index))\n",
    "df = pd.concat([df_rep, df_ref])\n",
    "print(len(df.index), len(list(set(list(df.index)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133852.3\n",
      "386585.9\n",
      "511145.12\n",
      "585056.7\n",
      "585057.6\n",
      "685038.3\n"
     ]
    }
   ],
   "source": [
    "for index in df_ref.index:\n",
    "    if df_ref.loc[index]['Genome Name'].find('Escherichia coli') != -1:\n",
    "#         print(df_ref.loc[index])\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "426px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "606px",
    "left": "0px",
    "right": "auto",
    "top": "106px",
    "width": "348px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
